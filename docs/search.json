[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Neuroimaging",
    "section": "",
    "text": "Welcome!\n\n\n\n\n\nTable 5.1: Course schedule\n\n\n\n\n\n\n\n\n\n\n\n\nSession #\nDate and time\nSpecific topic\nTODO for this class\nEstimated workload (h)\n\n\n1\n04.03.2025 | 13:30 | SR 02.31 (0002030122)\nOrganization and introduction\nnone\n0\n\n\n2\n11.03.2025 | 13:30 | SR 02.31 (0002030122)\nIntroduction to fMRI\nMake groups, start thinking of a project;\nInstall PsychoPy\n4\n\n\n3\n18.03.2025 | 13:30 | SR 02.31 (0002030122)\nProject slam and public vote\n(Winner does not need to write an interoduction)\nPrepare a presentation of your project (See Presentation Guidelines and Presentation Evaluation Criteria)\n4\n\n\n4\n25.03.2025 | 13:30 | SR 02.31 (0002030122)\nImplementation slam and second public vote\n(Winner does not need to write the experiment description)\nGo through the PsychoPy intro.\nImplement your project in PsychoPy, show it to the class\n8\n\n\n5\n01.04.2025 | 13:30 | SR 02.31 (0002030122)\nData management I\nNeurodesk registration\n4\n\n\n6\n08.04.2025 | 13:30 | SR 02.31 (0002030122)\nExperiment feedback, data management II;\nData acquisition in the MRI lab 9.04.2025\nEvery course participant performs 3 rounds of the experiment and gives feedback\n1\n\n\n7\n29.04.2025 | 13:30 | SR 02.31 (0002030122)\nPreprocessing\nMRIQC\n0\n\n\n8\n06.05.2025 | 13:30 | SR 02.31 (0002030122)\nAnalysis: General linear model\nPreprocessing\n4\n\n\n9\n13.05.2025 | 13:30 | SR 02.31 (0002030122)\nResult visualization and reporting\nVolume space analysis\n4\n\n\n10\n20.05.2025 | 13:30 | SR 02.31 (0002030122)\nAnalysis: Other analyses types\nSurface space analysis\n4\n\n\n11\n27.05.2025 | 13:30 | SR 02.31 (0002030122)\nResult presentation slam, public vote\n(winner does not need to write a results section)\nPrepare a poster with images\n4\n\n\n12\n03.06.2025 | 13:30 | SR 02.31 (0002030122)\nWriting an fMRI article\nReport draft: Results section\n4\n\n\n13\n17.06.2025 | 13:30 | SR 02.31 (0002030122)\nFinal session (study examples), course evaluation\nReport draft\n4\n\n\n14\n24.06.2025 | 13:30 | SR 02.31 (0002030122)\nReport deadline\n\n4",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Course Syllabus",
    "section": "",
    "text": "Lecturer\nCitation from UGOnline:\nNatalia Zaretskaya\nGroup Leader of the “Visual Neuroscience Lab”",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#contact-information",
    "href": "syllabus.html#contact-information",
    "title": "Course Syllabus",
    "section": "Contact information",
    "text": "Contact information\n\nnatalia.zaretskaya@uni-graz.at\nOffice hours: Tuesdays 10:00-11:30, sign up via https://doodle.com/bp/nataliazaretskaya/book-a-time\nTalk informally after class",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#other-courses",
    "href": "syllabus.html#other-courses",
    "title": "Course Syllabus",
    "section": "Other courses",
    "text": "Other courses\nSS 2025\n\nBSc SE “Neural Mechanisms of Consciousness”\nMSc SE “Advanced Neuroimaging Methods”\n\nWS 2025\n\nBSc VL “General Psychology I: Perception and Attention”\nBSc KS “Selected Studies in General Psychology”",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#research-interests",
    "href": "syllabus.html#research-interests",
    "title": "Course Syllabus",
    "section": "Research interests",
    "text": "Research interests\n\n\n\nFor details, see https://neurovision.uni-graz.at/en/research-directions/",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#organisatory-aspects",
    "href": "syllabus.html#organisatory-aspects",
    "title": "Course Syllabus",
    "section": "Organisatory aspects",
    "text": "Organisatory aspects\n\nLet’s be “per du” (Natalia)\nCourse language is English, but I speak German\nLet’s be less formal (please interrupt and ask questions!)\nCourse materials on Moodle: https://moodle.uni-graz.at",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#content-of-the-course",
    "href": "syllabus.html#content-of-the-course",
    "title": "Course Syllabus",
    "section": "Content of the course",
    "text": "Content of the course\n\n“Hard” knowledge\n\nBasics of performing an fMRI experiment\nModern practices in fMRI data analysis\nOpen science practices in Neuroimaging\n\n\n\n“Soft” skills\n\nScientific presentations\nScientific writing\nCritical thinking",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#goals",
    "href": "syllabus.html#goals",
    "title": "Course Syllabus",
    "section": "Goals",
    "text": "Goals\n\nUnderstand the possibilities and limitations of functional MRI\nBe able to plan, conduct, analyze and interpret fMRI experiments in practice\nKnow and apply open science practices in the field of neuroimaging",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#possible-workload-for-4-ects",
    "href": "syllabus.html#possible-workload-for-4-ects",
    "title": "Course Syllabus",
    "section": "Possible workload for 4 ECTS",
    "text": "Possible workload for 4 ECTS\n\n\n\n\nTable 1: Example workload distribution according to 4 ECTS (100 hours)\n\n\n\n\n\n\n\n\n\n\n\nActivity\nHours per week\nTotal hours\nCumulative sum\n\n\n\n\nClassroom\n14 x 1.5 hours\n21\n21\n\n\nIndividual/group work\n14 x 4\n56\n77\n\n\nReport writing\n\n23 hours ⁓ 3 full work days!\n100\n\n\nTotal\n\n100",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-requirements",
    "href": "syllabus.html#course-requirements",
    "title": "Course Syllabus",
    "section": "Course requirements",
    "text": "Course requirements\n\nActive participation in class (not graded)\n\nAttendance (maximum 2 absences are tolerated)\nContribution to class work/discussions\nHomework submissions (see the Course Schedule Table)\n\n25%: Project concept presentation (individual or group)\n25%: Result visualization presentation (individual or group)\n50 %: Final report (individual)\n\nAfter the deadline the grade decreases by 1 point per 24 hours\n\nCourse feedback confirmation\n\nSubmission of an UGOnline screenshot to Moodle before semester end",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#sec-presentation-evaluation",
    "href": "syllabus.html#sec-presentation-evaluation",
    "title": "Course Syllabus",
    "section": "Evaluation criteria",
    "text": "Evaluation criteria\n\nProject presentation\n\nScientific merit\nFeasibility\n\nVisualization presentation\n\nClarity in conveying the message\nScientific correctness\n\nReport\n\nFormal correctness (see guidelines below)\nUnderstanding of all stages of course work",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#sec-presentation-guidelines",
    "href": "syllabus.html#sec-presentation-guidelines",
    "title": "Course Syllabus",
    "section": "Presentation guidelines",
    "text": "Presentation guidelines\n\n\nDuration 5-10 minutes\nAspects to address\n\nGeneral relevance of the topic\n1-2 articles on the topic\nSpecific research question\nWhy is fMRI necessary?\nSpecific experimental conditions…?",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#report-guidelines",
    "href": "syllabus.html#report-guidelines",
    "title": "Course Syllabus",
    "section": "Report guidelines",
    "text": "Report guidelines\n\n\nIntroduction: maximum 500 words\nMethods: max 1000 words\n\nParticipant\nExperimental paradigm\nData acquisition\nData analysis\n\nResults: maximum 500 words\nDiscussion: maximum 500 words\nReferences",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#sec-ai-uni",
    "href": "syllabus.html#sec-ai-uni",
    "title": "Course Syllabus",
    "section": "AI usage (official)",
    "text": "AI usage (official)\nThe use of generative AI is generally possible in this course. Please note, however, that you as a student bear full responsibility for the accuracy of the generated content.\nAn academic integrity statement is required for each submitted paper, the verbatim copying of AI-generated text passages must be marked - analogous to conventional citations - by stating the AI system and the specification of the interaction (see “Orientation guidelines for dealing with text-generating AI systems at the University of Graz”, p. 1-2).\nIt is only prohibited to submit work that was created predominantly or even exclusively using generative AI.\nWhen using generative AI, please ensure that your submissions do not violate the rights of third parties, including copyright, personal rights, and data protection regulations.",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#sec-ai-course",
    "href": "syllabus.html#sec-ai-course",
    "title": "Course Syllabus",
    "section": "AI usage (this course)",
    "text": "AI usage (this course)\nAI usage is conditional on full disclosure:\n\n250 words maximum attachment to the report with a description of which AI tools were used and how exactly were they applied\nYou bare responsibility for the correctness and authorship of the written text\nI keep the right to invite you and ask questions about the content",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-schedule",
    "href": "syllabus.html#course-schedule",
    "title": "Course Syllabus",
    "section": "Course schedule",
    "text": "Course schedule\n\n\n\n\nTable 5.1: Course schedule\n\n\n\n\n\n\n\n\n\n\n\n\nSession #\nDate and time\nSpecific topic\nTODO for this class\nEstimated workload (h)\n\n\n1\n04.03.2025 | 13:30 | SR 02.31 (0002030122)\nOrganization and introduction\nnone\n0\n\n\n2\n11.03.2025 | 13:30 | SR 02.31 (0002030122)\nIntroduction to fMRI\nMake groups, start thinking of a project;\nInstall PsychoPy\n4\n\n\n3\n18.03.2025 | 13:30 | SR 02.31 (0002030122)\nProject slam and public vote\n(Winner does not need to write an interoduction)\nPrepare a presentation of your project (See Presentation Guidelines and Presentation Evaluation Criteria)\n4\n\n\n4\n25.03.2025 | 13:30 | SR 02.31 (0002030122)\nImplementation slam and second public vote\n(Winner does not need to write the experiment description)\nGo through the PsychoPy intro.\nImplement your project in PsychoPy, show it to the class\n8\n\n\n5\n01.04.2025 | 13:30 | SR 02.31 (0002030122)\nData management I\nNeurodesk registration\n4\n\n\n6\n08.04.2025 | 13:30 | SR 02.31 (0002030122)\nExperiment feedback, data management II;\nData acquisition in the MRI lab 9.04.2025\nEvery course participant performs 3 rounds of the experiment and gives feedback\n1\n\n\n7\n29.04.2025 | 13:30 | SR 02.31 (0002030122)\nPreprocessing\nMRIQC\n0\n\n\n8\n06.05.2025 | 13:30 | SR 02.31 (0002030122)\nAnalysis: General linear model\nPreprocessing\n4\n\n\n9\n13.05.2025 | 13:30 | SR 02.31 (0002030122)\nResult visualization and reporting\nVolume space analysis\n4\n\n\n10\n20.05.2025 | 13:30 | SR 02.31 (0002030122)\nAnalysis: Other analyses types\nSurface space analysis\n4\n\n\n11\n27.05.2025 | 13:30 | SR 02.31 (0002030122)\nResult presentation slam, public vote\n(winner does not need to write a results section)\nPrepare a poster with images\n4\n\n\n12\n03.06.2025 | 13:30 | SR 02.31 (0002030122)\nWriting an fMRI article\nReport draft: Results section\n4\n\n\n13\n17.06.2025 | 13:30 | SR 02.31 (0002030122)\nFinal session (study examples), course evaluation\nReport draft\n4\n\n\n14\n24.06.2025 | 13:30 | SR 02.31 (0002030122)\nReport deadline\n\n4",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#recommended-reading",
    "href": "syllabus.html#recommended-reading",
    "title": "Course Syllabus",
    "section": "Recommended reading",
    "text": "Recommended reading\nWill be announced as we go along",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#qa",
    "href": "syllabus.html#qa",
    "title": "Course Syllabus",
    "section": "Q&A",
    "text": "Q&A\n\nYou can also ask questions in Moodle forum",
    "crumbs": [
      "Course Syllabus"
    ]
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Course overview",
    "section": "",
    "text": "Stages of an fMRI study",
    "crumbs": [
      "Course overview"
    ]
  },
  {
    "objectID": "overview.html#stages-of-an-fmri-study",
    "href": "overview.html#stages-of-an-fmri-study",
    "title": "Course overview",
    "section": "",
    "text": "Idea/research question\nExperimental implementation\nData acquisition\nData analysis\nPaper writing",
    "crumbs": [
      "Course overview"
    ]
  },
  {
    "objectID": "overview.html#implementation",
    "href": "overview.html#implementation",
    "title": "Course overview",
    "section": "Implementation",
    "text": "Implementation\n\nhttps://www.psychopy.org/",
    "crumbs": [
      "Course overview"
    ]
  },
  {
    "objectID": "overview.html#data-acquisition",
    "href": "overview.html#data-acquisition",
    "title": "Course overview",
    "section": "Data acquisition",
    "text": "Data acquisition\n\nhttps://mri-lab.uni-graz.at/en/\nKopernikusgasse 24 (Graz University of Technology - “Neue Technik”)",
    "crumbs": [
      "Course overview"
    ]
  },
  {
    "objectID": "overview.html#data-analysis",
    "href": "overview.html#data-analysis",
    "title": "Course overview",
    "section": "Data analysis",
    "text": "Data analysis\n\nhttps://www.neurodesk.org/",
    "crumbs": [
      "Course overview"
    ]
  },
  {
    "objectID": "overview.html#neurodesk-access-on-visual-neuroscience-server",
    "href": "overview.html#neurodesk-access-on-visual-neuroscience-server",
    "title": "Course overview",
    "section": "Neurodesk access on Visual Neuroscience Server",
    "text": "Neurodesk access on Visual Neuroscience Server\n\nUniversitätsplatz 2, Top floor\nhttps://psychologie.uni-graz.at/en/",
    "crumbs": [
      "Course overview"
    ]
  },
  {
    "objectID": "overview.html#neurodesktop",
    "href": "overview.html#neurodesktop",
    "title": "Course overview",
    "section": "Neurodesktop",
    "text": "Neurodesktop",
    "crumbs": [
      "Course overview"
    ]
  },
  {
    "objectID": "fmri-intro.html",
    "href": "fmri-intro.html",
    "title": "1  Introduction to fMRI",
    "section": "",
    "text": "fMRI study examples",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#fmri-study-examples",
    "href": "fmri-intro.html#fmri-study-examples",
    "title": "1  Introduction to fMRI",
    "section": "",
    "text": "Many crazy studies have been performed with fMRI. Not all of the research questions really make sense!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#fmri-in-comparison",
    "href": "fmri-intro.html#fmri-in-comparison",
    "title": "1  Introduction to fMRI",
    "section": "fMRI in comparison",
    "text": "fMRI in comparison\n\n\n\nSource: Gazzaniga 5th edition, Figure 3.45",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#mri-scanner-3-tesla",
    "href": "fmri-intro.html#mri-scanner-3-tesla",
    "title": "1  Introduction to fMRI",
    "section": "MRI scanner: 3 Tesla",
    "text": "MRI scanner: 3 Tesla\n\n\n\nhttps://mri-lab.uni-graz.at/",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#mri-scanner-7-tesla",
    "href": "fmri-intro.html#mri-scanner-7-tesla",
    "title": "1  Introduction to fMRI",
    "section": "MRI scanner: 7 Tesla",
    "text": "MRI scanner: 7 Tesla\n\n\n\nImage source: Medical University of Vienna",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#mri-scanner-9.4-tesla",
    "href": "fmri-intro.html#mri-scanner-9.4-tesla",
    "title": "1  Introduction to fMRI",
    "section": "MRI scanner: 9.4 Tesla",
    "text": "MRI scanner: 9.4 Tesla\n\n\n\nImage source: Max-Planck Institute for Biological Cybernetics, Tübingen",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#types-of-mri-contrasts",
    "href": "fmri-intro.html#types-of-mri-contrasts",
    "title": "1  Introduction to fMRI",
    "section": "Types of MRI contrasts",
    "text": "Types of MRI contrasts\n\n\n\nImage source: https://en.wikipedia.org/wiki/Magnetic_resonance_imaging",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#t1w-in-cognitive-neuroscience",
    "href": "fmri-intro.html#t1w-in-cognitive-neuroscience",
    "title": "1  Introduction to fMRI",
    "section": "T1w in cognitive neuroscience",
    "text": "T1w in cognitive neuroscience\n\n\n\nFull Segmentation of a T1-weighted scan (Zaretskaya et al. 2018)\n\n\nDisplaying activity on a high-resolution anatomical scan\nQuantitative morphometry\n\nAging\nNeurodegeneration\nPlasticity",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#the-principle-of-fmri",
    "href": "fmri-intro.html#the-principle-of-fmri",
    "title": "1  Introduction to fMRI",
    "section": "The principle of fMRI",
    "text": "The principle of fMRI\n\n\n\nImage source: https://www.nature.com/scitable/blog/brain-metrics/what_does_fmri_measure\n\nHemodynamic changes: - increase in blood flow - increase in blood volume - increase in tissue CMRO_2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#hemodynamic-response",
    "href": "fmri-intro.html#hemodynamic-response",
    "title": "1  Introduction to fMRI",
    "section": "Hemodynamic response",
    "text": "Hemodynamic response\n\n\n\nSource: Visual Neuroscience Lab",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#bold-signal",
    "href": "fmri-intro.html#bold-signal",
    "title": "1  Introduction to fMRI",
    "section": "BOLD signal",
    "text": "BOLD signal\nblood-oxygen-level-dependent signal\n\n\n\nHemodynamics leading to the BOLD signal (“Interpreting the BOLD Response” 2009)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#t2-weighted-contrast",
    "href": "fmri-intro.html#t2-weighted-contrast",
    "title": "1  Introduction to fMRI",
    "section": "T2*-weighted contrast",
    "text": "T2*-weighted contrast",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#hemodynamic-response-function",
    "href": "fmri-intro.html#hemodynamic-response-function",
    "title": "1  Introduction to fMRI",
    "section": "Hemodynamic response function",
    "text": "Hemodynamic response function\n\n\nThis curve describes the measured signal in response to a brief stimulus.\nThe response is heavily delayed, and has a relatively complex temporal structure, described by the so called hemodynamic response function (HRF).\nAfter just a brief stimulus that lasts less than a second, the response lasts for seconds. It has a delayed rise phase, a peak, and a subsequent undershoot. The fact that the response is so slow is the main constraint of the temporal resolution of fMRI. It constrains the kind of questions you can ask in your experiment and also puts some constraints on your experimental design.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#neural-activity-and-bold",
    "href": "fmri-intro.html#neural-activity-and-bold",
    "title": "1  Introduction to fMRI",
    "section": "Neural activity and BOLD",
    "text": "Neural activity and BOLD\n\n\n\nBOLD signal correlates better with LFP than with MUA (Logothetis et al. 2001)\n\nLFP = Local Field Potentials (dendritic currents)\nMUA = Multiunit Activity (action potentials)\nSDF = Spike-density function (action potentials)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#image-acquisition",
    "href": "fmri-intro.html#image-acquisition",
    "title": "1  Introduction to fMRI",
    "section": "Image acquisition",
    "text": "Image acquisition\n\n\nThe functional volume is usually acquired slice-by-slice; this is why when you are acquiring the data you see an image like this on the monitor. A functional sequence is characterized by the in-plane matrix size and resolution, as well as by the slice thickness.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#experimental-design",
    "href": "fmri-intro.html#experimental-design",
    "title": "1  Introduction to fMRI",
    "section": "Experimental design",
    "text": "Experimental design\n\n\nIn contrast to e.g. fNIRS, the BOLD-fMRI does not measure the deoxyhemoglobin concentration directly. It is a measure that is weighted by the deoxyhemoglobin concentration, but depends on many other factors like scanner, sequence, participant, and brain area.\nThis is why any measure of fMRI experiment has to contain at least two conditions, a baseline, and condition of interest. The activation is always computed relative to some baseline. For instance a checkerboard vs gray background, finger tapping versus rest; faces versus houses, etc. And a typical analysis will compare the BOLD signal during condition of interest with rest.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#first-fmri-experiment",
    "href": "fmri-intro.html#first-fmri-experiment",
    "title": "1  Introduction to fMRI",
    "section": "First fMRI experiment",
    "text": "First fMRI experiment\n\n\n\nBrain images and statistical analysis (Belliveau et al. 1991)\n\nThe first experiment was not a BOLD, but a blood volume signal measurement.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#first-fmri-experiment-1",
    "href": "fmri-intro.html#first-fmri-experiment-1",
    "title": "1  Introduction to fMRI",
    "section": "First fMRI experiment",
    "text": "First fMRI experiment\n\n\n\nCover of the science magazine where the paper was published (Belliveau et al. 1991)\n\nThis rendering was produced specifically for the cover",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#the-truly-first-fmri-experiment",
    "href": "fmri-intro.html#the-truly-first-fmri-experiment",
    "title": "1  Introduction to fMRI",
    "section": "The truly first fMRI experiment",
    "text": "The truly first fMRI experiment\n\n\n\nExperimental setup of Angelo Mosso (Sandrone et al. 2013)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#a-typical-experiment",
    "href": "fmri-intro.html#a-typical-experiment",
    "title": "1  Introduction to fMRI",
    "section": "A typical experiment",
    "text": "A typical experiment\n\n\nTo help us better understand the analysis steps, let’s use an example. Let’s say we have conducted a classical experiment in the visual system, a flickering checkerboard. In this experiment, we want to find out which brain areas are active when subjects view a flickering checkerboard compared to when they view a gray background. We have shown to every volunteer a checkerboard for e.g. 20 second interleaved with a 20 s rest, and we will measure a whole brain volume every 2 seconds, for e.g. to minutes or so.\nMatlab code to generate stimulus, BOLD and shifted BOLD X = [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]; bf = spm_get_bf; % indicated a tr of 2.5 Y = conv(X,bf.bf); Ye = Y+randn(size(Y)).*0.2;",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#d-dataset",
    "href": "fmri-intro.html#d-dataset",
    "title": "1  Introduction to fMRI",
    "section": "4D dataset",
    "text": "4D dataset\n\n\nIn a functional experiment we usually measure brain activity across the whole volume over extended periods of time, so it is comfortable to think about each functional dataset that we acquire as a 4D dataset, which consists of 3D brain volumes and time as a 4th dimension. This is how the data is typically stored.\nA further important parameter is the repetition time (TR). It is the time passes between the acquisition times of two adjacent volumes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#preprocessing",
    "href": "fmri-intro.html#preprocessing",
    "title": "1  Introduction to fMRI",
    "section": "Preprocessing",
    "text": "Preprocessing\n\n\n\nSummary of preprocessing steps (Esteban et al. 2018)\n\nThe data quality of modern scanners is typically good enough to skip this step, if your subject is compliant. But it is nevertheless very much advisable and is ALWAYS performed. We will therefore dedicate a whole session to preprocessing. See course schedule for the date.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#sec-analysis-steps",
    "href": "fmri-intro.html#sec-analysis-steps",
    "title": "1  Introduction to fMRI",
    "section": "Analysis steps",
    "text": "Analysis steps\n\nSingle-subject - first level - fixed effects analysis (FFX)\nGroup - second-level - random effects analysis (RFX)\n\n\nThis is equivalent to e.g. conducting many trials per subject to measure reaction time, and then compute a subject-specific mean per condition, after which you would perform the actual statistical inference\nMultilevel modelling is also possible (for small datasets), but less frequent.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#single-subject-first-level-analysis",
    "href": "fmri-intro.html#single-subject-first-level-analysis",
    "title": "1  Introduction to fMRI",
    "section": "Single-subject (first-level) analysis",
    "text": "Single-subject (first-level) analysis\nUnivariate/voxel-wise analysis\n\nQuestion: Which areas are activated by the flickering checkerboard?\n\nRemember that an image is 4d and consists of little 3D cubes called voxels, with the 4th dimension being time. A classical analysis is done over time for every voxel in the brain independently.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#stimulus-function",
    "href": "fmri-intro.html#stimulus-function",
    "title": "1  Introduction to fMRI",
    "section": "Stimulus function",
    "text": "Stimulus function\n\n\nLet’s recall our checkerboard experiment where participants viewed either a checkerboard or a gray screen. Let’s also create a function, called “stimulus function”, which is one where the checkerboard was on, and zero where the checkerboard was off",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#side-note-on-terminology",
    "href": "fmri-intro.html#side-note-on-terminology",
    "title": "1  Introduction to fMRI",
    "section": "Side-note on terminology",
    "text": "Side-note on terminology\n\nTrial\nContinuous presentation of 1 experimental condition, usually 1-20 seconds\n\n\nRun\nBlock of trials separated by interruption of a scanner acquisition, usually 5-10 minutes\n\n\nSession\nBlock of runs, separated by subject going out of the scanner and going in again, usually at least one day",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#voxel-time-course",
    "href": "fmri-intro.html#voxel-time-course",
    "title": "1  Introduction to fMRI",
    "section": "Voxel time course",
    "text": "Voxel time course\n\n\nLet’s now look at the time course of a voxel in the visual cortex. You see that it is noisy and delayed, but it kind of follows the stimulus.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#simplest-analysis-temporal-alignment",
    "href": "fmri-intro.html#simplest-analysis-temporal-alignment",
    "title": "1  Introduction to fMRI",
    "section": "Simplest analysis: temporal alignment",
    "text": "Simplest analysis: temporal alignment\n\n\nThe simplest analysis would be to realign the BOLD time course with the stimulus time course",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#simplest-analysis-statistical-inference",
    "href": "fmri-intro.html#simplest-analysis-statistical-inference",
    "title": "1  Introduction to fMRI",
    "section": "Simplest analysis: statistical inference",
    "text": "Simplest analysis: statistical inference\n\n\nThen labael each value according to when it was acquired, stimulus or baseline Collect two types of data points into two big piles and do a statistical comparison via a t-test",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#simplest-analysis-statistical-map",
    "href": "fmri-intro.html#simplest-analysis-statistical-map",
    "title": "1  Introduction to fMRI",
    "section": "Simplest analysis: statistical map",
    "text": "Simplest analysis: statistical map\n\n\nIf you do it for every voxel, you can get a new volume, which consists of t-statistics",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#general-linear-model-glm",
    "href": "fmri-intro.html#general-linear-model-glm",
    "title": "1  Introduction to fMRI",
    "section": "General Linear Model (GLM)",
    "text": "General Linear Model (GLM)\nMultiple regression with ingredients:\n\nPredictor(s): stimulus function convolved with the HRF (see Buidling regressors)\nNuissance regressors",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#buidling-regressors",
    "href": "fmri-intro.html#buidling-regressors",
    "title": "1  Introduction to fMRI",
    "section": "Buidling regressors",
    "text": "Buidling regressors\n\n\n\nSome convolution examples can be found here (Lindquist 2008)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#general-linear-model",
    "href": "fmri-intro.html#general-linear-model",
    "title": "1  Introduction to fMRI",
    "section": "General linear model",
    "text": "General linear model",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#statistical-inference-in-whole-brain-analysis",
    "href": "fmri-intro.html#statistical-inference-in-whole-brain-analysis",
    "title": "1  Introduction to fMRI",
    "section": "Statistical inference in whole-brain analysis",
    "text": "Statistical inference in whole-brain analysis\n\n\nHow do we get from beta estimates to making statistical inference? As in a typical regression, beta estimate divided by its standard error is a t-statistic with a t-distribution. So to know whether an activation in one voxel is significant is relatively straightforward.\nIf we had just one voxel, we would have computed the t-statistic, and then depending on the degrees of freedom determined if it exceeds the critical value. However, we are doing the same statistical test for MANY voxels. SO the probability that we find a significant voxel simply by chance increases. This is the multiple comparison problem that is encountered anywhere in statistics. In fMRI it is particularly prominent, because the number if singe tests is enormous. There are several ways and philosophies for dealing with it, I won’t go into details right now. The important thing is that any voxel-wise analysis MUST deal with this problem in some way.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#two-conditions",
    "href": "fmri-intro.html#two-conditions",
    "title": "1  Introduction to fMRI",
    "section": "Two conditions",
    "text": "Two conditions",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#general-linear-model-with-two-conditions",
    "href": "fmri-intro.html#general-linear-model-with-two-conditions",
    "title": "1  Introduction to fMRI",
    "section": "General linear model with two conditions",
    "text": "General linear model with two conditions",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#contrast",
    "href": "fmri-intro.html#contrast",
    "title": "1  Introduction to fMRI",
    "section": "Contrast",
    "text": "Contrast\nA linear combination of beta estimates",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#glm-advantages",
    "href": "fmri-intro.html#glm-advantages",
    "title": "1  Introduction to fMRI",
    "section": "GLM advantages",
    "text": "GLM advantages\n\n\n\n\n\nComplex experimental designs\nDiscounting uninteresting effects/confounds\nHRF shape estimation",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#group-analysis",
    "href": "fmri-intro.html#group-analysis",
    "title": "1  Introduction to fMRI",
    "section": "Group analysis",
    "text": "Group analysis",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#region-of-interest-roi-analysis",
    "href": "fmri-intro.html#region-of-interest-roi-analysis",
    "title": "1  Introduction to fMRI",
    "section": "Region-of-interest (ROI) analysis",
    "text": "Region-of-interest (ROI) analysis\n\nQuestion: Does the primary visual cortex respond to flickering checkerboards?\n\n\nHCP cortical parcellation (“Glasser atlas”) (Glasser et al. 2016)\n\nROI analysis is a way to deal with multiple comparison problem. But it requires an a priory and independent definition of an ROI.\nThere are two ways to define ROIs:\n\nFrom an anatomical scan\nFrom an additional (separate) functional experiment",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#subcortical-rois",
    "href": "fmri-intro.html#subcortical-rois",
    "title": "1  Introduction to fMRI",
    "section": "Subcortical ROIs",
    "text": "Subcortical ROIs\n\n\n\nNextBrain parcellation containing 333 anatomical structures (Casamitjana et al. 2024)\n\nThis is the state-of-the-art for anatomically-based ROI definition based on deep learning",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "fmri-intro.html#references",
    "href": "fmri-intro.html#references",
    "title": "1  Introduction to fMRI",
    "section": "References",
    "text": "References\n\n\n\n\nBelliveau, J. W., D. N. Kennedy, R. C. McKinstry, B. R. Buchbinder, R. M. Weisskoff, M. S. Cohen, J. M. Vevea, T. J. Brady, and B. R. Rosen. 1991. “Functional Mapping of the Human Visual Cortex by Magnetic Resonance Imaging.” Science 254 (5032): 716–19. https://doi.org/10.1126/science.1948051.\n\n\nCasamitjana, Adrià, Matteo Mancini, Eleanor Robinson, Loïc Peter, Roberto Annunziata, Juri Althonayan, Shauna Crampsie, et al. 2024. “A Next-Generation, Histological Atlas of the Human Brain and Its Application to Automated Brain MRI Segmentation.” http://dx.doi.org/10.1101/2024.02.05.579016.\n\n\nCoates, Adam, David Linhardt, Christian Windischberger, Anja Ischebeck, and Natalia Zaretskaya. 2024. “High-Resolution 7T fMRI Reveals the Visual Zone of the Human Claustrum.” Imaging Neuroscience 2: 1–15. https://doi.org/10.1162/imag_a_00327.\n\n\nEsteban, Oscar, Christopher J. Markiewicz, Ross W. Blair, Craig A. Moodie, A. Ilkay Isik, Asier Erramuzpe, James D. Kent, et al. 2018. “fMRIPrep: A Robust Preprocessing Pipeline for Functional MRI.” Nature Methods 16 (1): 111–16. https://doi.org/10.1038/s41592-018-0235-4.\n\n\nGlasser, Matthew F., Timothy S. Coalson, Emma C. Robinson, Carl D. Hacker, John Harwell, Essa Yacoub, Kamil Ugurbil, et al. 2016. “A Multi-Modal Parcellation of Human Cerebral Cortex.” Nature 536 (7615): 171–78. https://doi.org/10.1038/nature18933.\n\n\n“Interpreting the BOLD Response.” 2009. In, 400–424. Cambridge University Press. https://doi.org/10.1017/cbo9780511605505.020.\n\n\nLindquist, Martin A. 2008. “The Statistical Analysis of fMRI Data.” Statistical Science 23 (4). https://doi.org/10.1214/09-sts282.\n\n\nLogothetis, Nikos K., Jon Pauls, Mark Augath, Torsten Trinath, and Axel Oeltermann. 2001. “Neurophysiological Investigation of the Basis of the fMRI Signal.” Nature 412 (6843): 150–57. https://doi.org/10.1038/35084005.\n\n\nSandrone, Stefano, Marco Bacigaluppi, Marco R. Galloni, Stefano F. Cappa, Andrea Moro, Marco Catani, Massimo Filippi, Martin M. Monti, Daniela Perani, and Gianvito Martino. 2013. “Weighing Brain Activity with the Balance: Angelo Mosso’s Original Manuscripts Come to Light.” Brain 137 (2): 621–33. https://doi.org/10.1093/brain/awt091.\n\n\nZaretskaya, Natalia, Bruce Fischl, Martin Reuter, Ville Renvall, and Jonathan R Polimeni. 2018. “Advantages of Cortical Surface Reconstruction Using Submillimeter 7 t MEMPRAGE.” NeuroImage 165 (January): 11–26. https://doi.org/10.1016/j.neuroimage.2017.09.060.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to fMRI</span>"
    ]
  },
  {
    "objectID": "paradigm.html",
    "href": "paradigm.html",
    "title": "2  Experimental paradigm",
    "section": "",
    "text": "Runs\nIn PsychoPy",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Experimental paradigm</span>"
    ]
  },
  {
    "objectID": "paradigm.html#runs",
    "href": "paradigm.html#runs",
    "title": "2  Experimental paradigm",
    "section": "",
    "text": "chunks of 5-10 minute length\none run - one start of the PsychoPy script",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Experimental paradigm</span>"
    ]
  },
  {
    "objectID": "paradigm.html#start-screen",
    "href": "paradigm.html#start-screen",
    "title": "2  Experimental paradigm",
    "section": "Start screen",
    "text": "Start screen\n\nThe script should start by showing a welcome message or instruction reminder\nIt should be waiting for key “5” (scanner “trigger”)\nThis is needed to synchronize the fMRI signal acquisition with your paradigm\nAfter the start screen, there should be a period of ca. 10 seconds of nothing happening; this is needed to discard initial artifacts",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Experimental paradigm</span>"
    ]
  },
  {
    "objectID": "paradigm.html#subject-responses",
    "href": "paradigm.html#subject-responses",
    "title": "2  Experimental paradigm",
    "section": "Subject responses",
    "text": "Subject responses\nSubject keys: 1, 2, 3, 4, [], 6, 7, 8, 9\n1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Experimental paradigm</span>"
    ]
  },
  {
    "objectID": "paradigm.html#bids-pluginparadigm-2-for-psychopy",
    "href": "paradigm.html#bids-pluginparadigm-2-for-psychopy",
    "title": "2  Experimental paradigm",
    "section": "BIDS plugin2 for PsychoPy",
    "text": "BIDS plugin2 for PsychoPy\nShould be installed and enabled to save events (conditions and button presses) in a comprehensive and standardized manner\n\nThis will also make our data analysis easier",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Experimental paradigm</span>"
    ]
  },
  {
    "objectID": "paradigm.html#footnotes",
    "href": "paradigm.html#footnotes",
    "title": "2  Experimental paradigm",
    "section": "",
    "text": "Current Designs https://www.curdes.com/mainforp/responsedevices/buttonboxes/hhsc-1x4-l.html↩︎\nhttps://psychopy-bids.readthedocs.io/en/stable/↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Experimental paradigm</span>"
    ]
  },
  {
    "objectID": "data_management.html",
    "href": "data_management.html",
    "title": "3  Data management",
    "section": "",
    "text": "General\nIn neuroimaging",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#general",
    "href": "data_management.html#general",
    "title": "3  Data management",
    "section": "",
    "text": "(Juavinett 2022)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#state-in-2022",
    "href": "data_management.html#state-in-2022",
    "title": "3  Data management",
    "section": "State in 2022",
    "text": "State in 2022\n\n\n\nImage credit: (Juavinett 2022)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#bids",
    "href": "data_management.html#bids",
    "title": "3  Data management",
    "section": "BIDS",
    "text": "BIDS",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#bids-plugin-for-psychopy",
    "href": "data_management.html#bids-plugin-for-psychopy",
    "title": "3  Data management",
    "section": "BIDS plugin for PsychoPy",
    "text": "BIDS plugin for PsychoPy\nShould be installed and enabled to save events (conditions and button presses) in a comprehensive and standardized manner.\n\nThis will also make our data analysis easier\n\n\nhttps://psychopy-bids.readthedocs.io/en/stable/",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#installation",
    "href": "data_management.html#installation",
    "title": "3  Data management",
    "section": "Installation",
    "text": "Installation\n\n\nOpen psychopy and press “Get more” on the right side. Alternatively you can open “plugin/pachages manager” via “Tools” menue. Psychopy-plugin should be listed among the available plugins.\nOn the university computers, bids plugin is available through software center.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#thanks-to",
    "href": "data_management.html#thanks-to",
    "title": "3  Data management",
    "section": "Thanks to",
    "text": "Thanks to\n\nLukas currently took over the BIDS plugin development.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#properties",
    "href": "data_management.html#properties",
    "title": "3  Data management",
    "section": "Properties",
    "text": "Properties\n\n\n\nExperiment name will correspond to the task-[taskname] properety in the bids dataset. It is therefore useful to have a short name without capital letters. This did not work on my mac, but maybe this is an OS issue?\nParticipant: switched from random code generator to 001. Since we keep the naming consistent with the MRI dataset, and have multiple runs, it is not useful to generate a new code on every run repetition\nSession: changed from 001 to 1. This is just our naming convention. Nobody has hundreds of sessions, so we do not expect a number with more than two digits.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#renaming",
    "href": "data_management.html#renaming",
    "title": "3  Data management",
    "section": "Renaming?",
    "text": "Renaming?\n\nFile\n\n\n\nProject folder\n\n\nFor the task label to work properly in the BIDS plugin, I also tried renaming the experiment file and the folder, but this did not help. Gambling is still spelled out with a capital “G” no mater what I do. Let’s stay tuned for the psychopy-bids updates.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#research-question",
    "href": "data_management.html#research-question",
    "title": "3  Data management",
    "section": "Research question",
    "text": "Research question\n\nWhat information do we actually need for analysis?\n\n\nWe should keep the research question in mind.\nH1 is formulated as a one-way ANOVA with three pairwise post-hoc tests\nH2 is formulated as 2x2 two-way ANOVA (at least we will simplify it to that)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#unique-conditions",
    "href": "data_management.html#unique-conditions",
    "title": "3  Data management",
    "section": "Unique conditions",
    "text": "Unique conditions\n\nsmall win\nsmall loss\nlarge win\nlarge loss\npass",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#trials.xlsx",
    "href": "data_management.html#trials.xlsx",
    "title": "3  Data management",
    "section": "trials.xlsx",
    "text": "trials.xlsx\n\n\nFor every trial, we should be able to identify whether it is win, loss or pass.\nFor every win or loss trial, we need to know if it is a win/loss with high stakes or with low stakes.\nNote: right now we are not taking the win probability into account, but we know that it is always low for large stakes, and large for low stakes, so it is redundant.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#side-note",
    "href": "data_management.html#side-note",
    "title": "3  Data management",
    "section": "Side note:",
    "text": "Side note:\n\nIdeal paradigm\n\nEach trial type appears the same number of times\nCarryover counterbalancing - each condition is equally likely to be preceded by each other condition (Brooks 2012)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#events-of-interest-in-a-trial",
    "href": "data_management.html#events-of-interest-in-a-trial",
    "title": "3  Data management",
    "section": "Events of interest in a trial",
    "text": "Events of interest in a trial\n\ngamble_trial or gamble_outcome?\n\n\n\nDo we need key presses?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#adding-bids-events",
    "href": "data_management.html#adding-bids-events",
    "title": "3  Data management",
    "section": "Adding bids events",
    "text": "Adding bids events\n\nScanner trigger\n\nI am not sure if it is needed after all, but I added a bids component to a routine that waits 10 seconds after the scanner trigger and logged its onset.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#linking-to-a-routine-1",
    "href": "data_management.html#linking-to-a-routine-1",
    "title": "3  Data management",
    "section": "Linking to a routine # 1",
    "text": "Linking to a routine # 1\n\n\nIn the BIDS Event Type field you can choose between TaskEvent and BehEvent. For now the difference does not matter much, let’s choose task event.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#linking-to-a-routine-2",
    "href": "data_management.html#linking-to-a-routine-2",
    "title": "3  Data management",
    "section": "Linking to a routine #2",
    "text": "Linking to a routine #2\n\nRight now time 0 in our experiment is the start of the welcome screen. We want time 0 to be the scanner trigger. Will take care of it later.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#adding-bids-events-of-interest",
    "href": "data_management.html#adding-bids-events-of-interest",
    "title": "3  Data management",
    "section": "Adding bids events of interest",
    "text": "Adding bids events of interest\n\nNew variable outcome_trial\nWe need one variable to take 3 possible outcomes: win, loss or pass. Therefore, I adjusted the code, adding a variable “outcome_trial” for this purpose.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#points_text",
    "href": "data_management.html#points_text",
    "title": "3  Data management",
    "section": "points_text",
    "text": "points_text\n\n\nWe are creating a bids event and linking it to points_text within the trial (because this routine appears on every loop interation).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#time-stamp",
    "href": "data_management.html#time-stamp",
    "title": "3  Data management",
    "section": "Time stamp",
    "text": "Time stamp\n\nTime 0 - scanning onset\n\n\nNow we want to adjust the onset time to the scanner trigger arrival. This is done by ticking “Manually set values” and putting the difference between the onset of the current routine and the start of the blank period.\nIt would have been better and more accurate to subtract the actually key press time, but I ran out of time.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#other-events",
    "href": "data_management.html#other-events",
    "title": "3  Data management",
    "section": "Other events",
    "text": "Other events\n\n\nHere I added two other bids events that may or may not be useful, just in case: Trial onset and key press, including reaction times.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#bids-export",
    "href": "data_management.html#bids-export",
    "title": "3  Data management",
    "section": "BIDS export",
    "text": "BIDS export\n\nIt is important to add the bidsExport routine at the end of the experiment.\n\nFor fMRI, the data type should be “func”\nChoose. your favourite license\nTick the box “Add Run Nubmers” - this should attach run numbers to the file names in bids format for every new run. I did not get it to work properly on mac (it was always run 1, overwriting the previous file). But supposedly it works on windows and linux.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#complete-bids-dataset",
    "href": "data_management.html#complete-bids-dataset",
    "title": "3  Data management",
    "section": "Complete BIDS dataset",
    "text": "Complete BIDS dataset\n\nExample\n\n\nThis is how a complete dataset for fmri analysis should look like. You should have functional _bold.nii.gz files and _events.tsv files in one func/ folder.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#neurodesk",
    "href": "data_management.html#neurodesk",
    "title": "3  Data management",
    "section": "Neurodesk",
    "text": "Neurodesk",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#mri-data-formats",
    "href": "data_management.html#mri-data-formats",
    "title": "3  Data management",
    "section": "MRI data formats",
    "text": "MRI data formats\n\nDICOM - medical image format\n\n.dcm .ima or nothing at all\n\nNIFTI - neuroimaging format we work with\n\n.nii or .nii.gz",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#bidscoin",
    "href": "data_management.html#bidscoin",
    "title": "3  Data management",
    "section": "bidscoin",
    "text": "bidscoin",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#shell-commands",
    "href": "data_management.html#shell-commands",
    "title": "3  Data management",
    "section": "Shell commands",
    "text": "Shell commands\n\n#!/bin/bash\n\n# you can copypaste the following commands into the terminal window that is opened by BIDSCOINER\n\n# define directories\nsourceFolder=/home/jovyan/completion2/dcm\nsortedFolder=/home/jovyan/completion2/dcm_sorted\n\n# check the output of the source folder\nls -l $sourceFolder\n\n# make the target directory with subdirectories\nmkdir -p $sortedFolder\n\n# change to the script folder\ncd /home/jovyan/dicomsort/\n\n# run the script\n./DICOMsort.sh $sourceFolder $sortedFolder\n\n# check the output of the target folder\nls -l $sortedFolder\n\n# run bidsmapper\nbidsmapper $sortedFolder /home/jovyan/completion2/bids\n# note: in the intendedFor of the fieldmap, add func/sub-001_ses-1_xxx_bold.*\n\n# once you are happy with the mapping, run bidscoiner\nbidscoiner $sortedFolder /home/jovyan/completion2/bids",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#bismapper",
    "href": "data_management.html#bismapper",
    "title": "3  Data management",
    "section": "bismapper",
    "text": "bismapper\n\nCurrently, to discover the data we need to delete the content of the “subprefix” field and then save the bids map in the default location. After this, run the same bidsmapper command again.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#subject-and-session",
    "href": "data_management.html#subject-and-session",
    "title": "3  Data management",
    "section": "Subject and session",
    "text": "Subject and session\n\nNow the bidsmapper discovered everything, but the files are not named correctly.\nEdit subject and session first.\nNow we need to rename the files by clicking “Edit” next to every file.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#editing-file-names-anatomical",
    "href": "data_management.html#editing-file-names-anatomical",
    "title": "3  Data management",
    "section": "Editing file names: anatomical",
    "text": "Editing file names: anatomical\n\nanatmprage -&gt; mprage in the “acq” filed",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#editing-file-names-functional",
    "href": "data_management.html#editing-file-names-functional",
    "title": "3  Data management",
    "section": "Editing file names: functional",
    "text": "Editing file names: functional\n\nEdit the task name and acq field\nDo this for every functional file\nIn the intendedFor of the fieldmap, add “func/sub-999_ses-1_task-completion_acq–noise_bold.*” with a wildcard. This will select all respective functional runs\nOnce you are happy, run bidscoiner to do the actual conversion",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#view-files",
    "href": "data_management.html#view-files",
    "title": "3  Data management",
    "section": "View files",
    "text": "View files",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#mricron",
    "href": "data_management.html#mricron",
    "title": "3  Data management",
    "section": "MRICron",
    "text": "MRICron\n\nNow you can view the nifti files with any suitable software",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#mriqc",
    "href": "data_management.html#mriqc",
    "title": "3  Data management",
    "section": "MRIQC",
    "text": "MRIQC\nMRIQC (Esteban et al. 2017)is a tool used for quality assurance of bids-valid datasets. It is a bids app, meaning that it works on bids-conform data.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#running-mriqc",
    "href": "data_management.html#running-mriqc",
    "title": "3  Data management",
    "section": "Running MRIQC",
    "text": "Running MRIQC\nShould take around 10 minutes\n\nCommand line\n# define relevant paths\nbids_folder=/home/jovyan/gambling/bids/\nmriqc_folder=/home/jovyan/gambling/bids/derivatives/mriqc/\n\n# create mriqc directory\nmkdir -p $mriqc_folder\n\n# run mriqc\nmriqc $bids_folder $mriqc_folder participant --participant-label 001\n\n\nOutput\n\n\nYou will see that there are html outputs for anatomical and functional scans. They can be viewed in a browser, without actually loading the images.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#anatomical",
    "href": "data_management.html#anatomical",
    "title": "3  Data management",
    "section": "Anatomical",
    "text": "Anatomical\n\n\nNoise\n\n\n\n\n\nActual image\n\n\n\n\n\nThis is useful to quickly identify problems with the data. A rating widget is also available, which is useful for large datasets.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#functional",
    "href": "data_management.html#functional",
    "title": "3  Data management",
    "section": "Functional",
    "text": "Functional\n\n\n\n\n\n\n\n\n\n\nFor functional data, in addition to spatial noise (middle) and average image over time (right), there is a section showing temporal noise over time. Note how the values are highest in the eyes (due to eye movements) and in the center of the brain, due to blood pulsation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#carpet-plots-for-functional-data",
    "href": "data_management.html#carpet-plots-for-functional-data",
    "title": "3  Data management",
    "section": "Carpet plots for functional data",
    "text": "Carpet plots for functional data\n\n\nCarpet plot shows signal fluctuations over time (x-axis) for each voxel (y-axis). Note how there are some patterns initially and at the end. There should be no clear pattern during the experiment, this speaks for good signal quality.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#references",
    "href": "data_management.html#references",
    "title": "3  Data management",
    "section": "References",
    "text": "References\n\n\n\n\nBrooks, Joseph L. 2012. “Counterbalancing for Serial Order Carryover Effects in Experimental Condition Orders.” Psychological Methods 17 (4): 600–614. https://doi.org/10.1037/a0029310.\n\n\nEsteban, Oscar, Daniel Birman, Marie Schaer, Oluwasanmi O. Koyejo, Russell A. Poldrack, and Krzysztof J. Gorgolewski. 2017. “MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites.” Edited by Boris C Bernhardt. PLOS ONE 12 (9): e0184661. https://doi.org/10.1371/journal.pone.0184661.\n\n\nJuavinett, Ashley L. 2022. “The Next Generation of Neuroscientists Needs to Learn How to Code, and We Need New Ways to Teach Them.” Neuron 110 (4): 576–78. https://doi.org/10.1016/j.neuron.2021.12.001.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "data_management.html#footnotes",
    "href": "data_management.html#footnotes",
    "title": "3  Data management",
    "section": "",
    "text": "valid for PsychoPy v2024.2.4↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data management</span>"
    ]
  },
  {
    "objectID": "preprocessing.html",
    "href": "preprocessing.html",
    "title": "4  Preprocessing",
    "section": "",
    "text": "Reminder: a typical experiment\nof an fMRI dataset",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#reminder-a-typical-experiment",
    "href": "preprocessing.html#reminder-a-typical-experiment",
    "title": "4  Preprocessing",
    "section": "",
    "text": "To help us better understand the preprocessing steps, let’s remind ourselves about a typical fMRI experiment with a flickering checkerboard. In this experiment, we want to find out which brain areas are active when subjects view a flickering checkerboard compared to when they view a gray background. We have shown to every volunteer a checkerboard for e.g. 20 second interleaved with a 20 s rest, and we will measure a whole brain volume every 2 seconds, for e.g. to minutes or so.\nMatlab code to generate stimulus, BOLD and shifted BOLD X = [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]; bf = spm_get_bf; % indicated a tr of 2.5 Y = conv(X,bf.bf); Ye = Y+randn(size(Y)).*0.2;",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#d-functional-dataset",
    "href": "preprocessing.html#d-functional-dataset",
    "title": "4  Preprocessing",
    "section": "4D functional dataset",
    "text": "4D functional dataset\n\n\nAnd, in a functional experiment we usually measure brain activity across the whole volume over extended perionds of time, so it is comfortable to think about each functional dataset that we acquire as a 4D dataset, which consists of 3D brain volumes and time as a 4th dimension.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#major-software",
    "href": "preprocessing.html#major-software",
    "title": "4  Preprocessing",
    "section": "Major software",
    "text": "Major software\n\n\n\n\n\n\n\n\n\nSince 1994 http://www.fil.ion.ucl.ac.uk/spm/\n\n\n\n\n\n\n\nSince 1994 http://afni.nimh.nih.gov/afni/\n\n\n\n\n\n\n\n\n\nSince 2000 http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/\n\n\n\n\n\n\n\nSince 1999 https://freesurfer.net/\n\n\n\n\n\n\nPreprocessing used to be integrated into the software used for the actual analysis. And there are many software for this. On this slide I just put a few of them. Each of them has a slightly different phylosophy behind it, but all of them do roughly the same thing, so at the end it should not matter much which of them you use.\nOne of the oldest ones are:\n\nSPM – statistical parameteric mapping from UCL. It is a free MATLAB-based toolbox. However, it depends on the MATLAB licence, and has not been updated for a long time. The new update just came out which spans the gab from 2012 to 2025 (Tierney et al. 2025).\nAFNI - from NIH\nFSL from Oxford – a set of linux tools, also free and independent of MATLAB, which is an advantage, but requires Linux.\nFreeSurfer/FSFAST form the Martinos center - it is Linux based, and was originally conceived as a tool for structural data analysis, but has an fMRI module\n\nHistorical software\n\nbroccolli, that can utilize GPU computing and can process the same dataset n times faster\n\nWith the awareness of open science, and with the trend towards reproducibility and transparency, and with the release of fMRIprep software, the preprocessing got detached from the actual data analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#fmriprep",
    "href": "preprocessing.html#fmriprep",
    "title": "4  Preprocessing",
    "section": "fMRIprep",
    "text": "fMRIprep\n\n\n\nImage source (Esteban et al. 2018)\n\nfMRIprep has evolved to combine best practices in fmri preprocessing and also to unify and standardize analysis steps. It is currently dominating the field and is the state-of-the-art way to do preprocessing.\nAll the steps we will talk about are implemented in fMRIprep.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#bias-field-correction",
    "href": "preprocessing.html#bias-field-correction",
    "title": "4  Preprocessing",
    "section": "Bias field correction",
    "text": "Bias field correction\n\n# gambling: view the before and after images by typing\nml freesurfer\nfreeview \\\n/home/jovyan/gambling/bids/sub-001/ses-1/anat/sub-001_ses-1_acq-mprage_T1w.nii.gz \\\n/home/jovyan/gambling/bids/derivatives/fmriprep/sub-001/ses-1/anat/sub-001_ses-1_acq-mprage_desc-preproc_T1w.nii.gz\n\nVarying intensities across the image will confuse subsequent steps.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#surface-reconstruction",
    "href": "preprocessing.html#surface-reconstruction",
    "title": "4  Preprocessing",
    "section": "Surface reconstruction",
    "text": "Surface reconstruction\n\n# gambling: view the reconstructed surfaces by typing\nml freesurfer\nfreeview \\\n/home/jovyan/gambling/bids/derivatives/fmriprep/sourcedata/freesurfer/sub-001/mri/orig.mgz \\\n-f /home/jovyan/gambling/bids/derivatives/fmriprep/sourcedata/freesurfer/sub-001/surf/*h.white \\\n/home/jovyan/gambling/bids/derivatives/fmriprep/sourcedata/freesurfer/sub-001/surf/*h.pial\n\nRelatively lengthy (some hours) multistage fully automatic process",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#normalization",
    "href": "preprocessing.html#normalization",
    "title": "4  Preprocessing",
    "section": "Normalization",
    "text": "Normalization\nWill be discussed in the section on functional data",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#non-steady-state-artifacts",
    "href": "preprocessing.html#non-steady-state-artifacts",
    "title": "4  Preprocessing",
    "section": "Non-steady-state artifacts",
    "text": "Non-steady-state artifacts\n\nAka T1 equilibration artifacts\n\n# gambling\nfile:///home/jovyan/gambling/bids/derivatives/mriqc/sub-001/figures/sub-001_ses-1_task-gambling_acq-Fs2_run-1_desc-carpet_bold.svg\n\nI could not really spot this artifact in the scans we acquired to show you. This may be due to two facts:\n\nOur scanner is quite good and modern, so these artifacts are minimal\nThe scanning protocol automatically acquires two volumes with those artifacts that are discarded\n\nPerhaps these large intensity fluctuations on the left (in the beginning) in this carpet plot reflect this.\nBut non-steady-state artifacts are actually the reason why I asked to include a 10-second period where nothing is happening into the experimental paradigm. Non-steady-state volumes should not overlap with the actual experimental paradigm. In the past, we waited for 4-5 volumes before the actual paradigm started, and then discarded these volumes during preprocessing, so that data and paradigm are temporally aligned. But the non-steady-state volumes have an advantage of having good gray-white matter contrast. Therefore, fMRIprep tries to automatically identify them for each run and use them to produce a “reference scan”, which is used in the subsequent steps.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#motion-correction",
    "href": "preprocessing.html#motion-correction",
    "title": "4  Preprocessing",
    "section": "Motion correction",
    "text": "Motion correction\n\nPurpose: compensate for subject movement\n\n\nOne of the first preprocessign steps is motion correction. Why do we need motion correction? During the fMRI experiment the subject is supposed to lay still inside the scanner, and they usually do so. However, even your best volunteer won’t be perfect. And in fMRI, even a few millimeters screw up your experiment. Here is an example. Let’s say we are measuring a voxel located on the left hemisphere, and the subject suddenly moved. As a result, the same voxel will be now recording activity from the empty space between the hemispheres, or even form the opposite hemisphere.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#motion-correction-1",
    "href": "preprocessing.html#motion-correction-1",
    "title": "4  Preprocessing",
    "section": "Motion correction",
    "text": "Motion correction\n6 parameter “rigid body” transform\n\n\nUsually, motion is much smaller, but we still want to correct it. How do we do this? Luckily there are special algorithms that can estimate the amount of motion from one volume to the next. This is usually done using 6 degrees of freedom: translation in x, y, and z and rotation in x, y, and z. This is called the “rigid body transform”, because you do not change the size and shape of the volume, but simply rotate it in space. After the amount of motion has been calculated, it can be applied to every image to align it back to the necessary position.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#plot-motion-parameters",
    "href": "preprocessing.html#plot-motion-parameters",
    "title": "4  Preprocessing",
    "section": "Plot motion parameters",
    "text": "Plot motion parameters",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#slice-time-correction",
    "href": "preprocessing.html#slice-time-correction",
    "title": "4  Preprocessing",
    "section": "Slice-time correction",
    "text": "Slice-time correction\n\nPurpose: compensate for the lag in slice acquisition\n\n\n\n\n\n\n \n\n\n \n\n\n\n\n\n\n\n\n\nThe next preprocessing step is slice-time correction. What is slice time correction and why do we need it? Remember that typically a functional volume is acquired not all at once, but slice-by-slice, as illustrated here. There are different ways in which the scanner can acquire the slices: it can bie botton-to top (ascending), decending, interleaved. There are also more complex slice acquisition patterns. Remember that the time it takes to acquire one volume is relatively long, in this our example it is 2 seconds. Let’s say a stimulus activates two areas, here and here in the same manner. If we acquire the slices in an asciending manner, we will measure a small signal amplitude in the frist area. By the time we arrive to the second area, the signal amplitude will increase in both areas, so we will measure a highre signal amplitude in the second area.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#slice-time-correction-1",
    "href": "preprocessing.html#slice-time-correction-1",
    "title": "4  Preprocessing",
    "section": "Slice-time correction",
    "text": "Slice-time correction\n\n\nHere is another way of illustrating the same issue. The purpose of the slice-time correction realigns signals from all slices in time as if they were acquired at the same time.\nMostly relevant for event-related designs or timing comparisons Can be substituted by modeling HRF derivatives if you are not interested in timing/time course analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#slice-time-correction-before-or-after-motion-correction",
    "href": "preprocessing.html#slice-time-correction-before-or-after-motion-correction",
    "title": "4  Preprocessing",
    "section": "Slice time correction: before or after motion correction?",
    "text": "Slice time correction: before or after motion correction?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#simultaneous-multislice-smsmultiband-mb-acquisitions",
    "href": "preprocessing.html#simultaneous-multislice-smsmultiband-mb-acquisitions",
    "title": "4  Preprocessing",
    "section": "Simultaneous multislice (SMS)/multiband (MB) acquisitions",
    "text": "Simultaneous multislice (SMS)/multiband (MB) acquisitions",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#susceptibility-distortions",
    "href": "preprocessing.html#susceptibility-distortions",
    "title": "4  Preprocessing",
    "section": "Susceptibility distortions",
    "text": "Susceptibility distortions\n\n\n\n\n\n\n\n\n\nImage source: https://mriquestions.com/susceptibility-artifact.html",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#field-map",
    "href": "preprocessing.html#field-map",
    "title": "4  Preprocessing",
    "section": "Field map",
    "text": "Field map\n\n\n\nImage source: https://mriquestions.com/susceptibility-artifact.html",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#reverse-pe-polarity",
    "href": "preprocessing.html#reverse-pe-polarity",
    "title": "4  Preprocessing",
    "section": "Reverse PE polarity",
    "text": "Reverse PE polarity\n\n\n\n\nA&gt;P vs. P&gt;A\n\n\n\n\n\n.\n\n\n\n# gambling: to view these images, type in the terminal:\nml freesurfer\nfreeview \\\n/home/jovyan/gambling/bids/sub-001/ses-1/func/sub-001_ses-1_task-gambling_acq-Fs2_run-1_bold.nii.gz \\\n/home/jovyan/gambling/bids/sub-001/ses-1/fmap/sub-001_ses-1_acq-Fs2_dir-PA_epi.nii.gz \\\n-ras 3 61 28",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#apply-the-deformation-field",
    "href": "preprocessing.html#apply-the-deformation-field",
    "title": "4  Preprocessing",
    "section": "Apply the deformation field",
    "text": "Apply the deformation field\n\n\n\n\nfile:///home/jovyan/gambling/bids/derivatives/fmriprep/sub-001.html\n\nHere you can see how e.g. the copmpressed inferior frontal lobe regions get unwarped (although lost signal can’t be recovered completely).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#co-registration",
    "href": "preprocessing.html#co-registration",
    "title": "4  Preprocessing",
    "section": "Co-registration",
    "text": "Co-registration\n\n\n\n\n2.5 mm iso T2*w vs. 1 mm iso T1w\n\n\n\n\n\n2.5 mm iso T2*w vs. 1 mm iso T1w\n\n\n\n# gambling: \nml freesurfer\nfreeview '\n/home/jovyan/gambling/bids/sub-001/ses-1/anat/sub-001_ses-1_acq-mprage_T1w.nii.gz \\\n/home/jovyan/gambling/bids/sub-001/ses-1/func/sub-001_ses-1_task-gambling_acq-Fs2_run-1_bold.nii.gz\n\nPurpose #1: view individual activation on a high quality anatomical image\nPurpose #2: mapping to standard space (normalization)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#mutual-information-maximization",
    "href": "preprocessing.html#mutual-information-maximization",
    "title": "4  Preprocessing",
    "section": "Mutual information maximization",
    "text": "Mutual information maximization\n\n\n\nCode\n# source: chatgpt\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import shift\nfrom sklearn.metrics import mutual_info_score\n\ndef create_realistic_fish(size=100):\n    img = np.zeros((size, size))\n    cx, cy = size // 2, size // 2\n\n    # Draw backbone (slight curve)\n    for x in range(20, 80):\n        y = int(cy + 5 * np.sin((x - 20) / 60 * np.pi))  # slight wave\n        img[x, y] = 1\n\n    # Draw ribs (angled lines)\n    for x in range(25, 75, 5):\n        y = int(cy + 5 * np.sin((x - 20) / 60 * np.pi))\n        for dy in range(1, 8):\n            if 0 &lt;= y - dy &lt; size:\n                img[x, y - dy] = 1\n            if 0 &lt;= y + dy &lt; size:\n                img[x, y + dy] = 1\n\n    # Draw head (big circle)\n    for i in range(-10, 11):\n        for j in range(-10, 11):\n            if i**2 + j**2 &lt; 100:\n                xi = 20 + i\n                yj = cy + j\n                if 0 &lt;= xi &lt; size and 0 &lt;= yj &lt; size:\n                    img[xi, yj] = 1\n\n    # Draw eye (small dot)\n    img[17, cy + 5] = 0  # black eye (making a small black pixel inside head)\n\n    # Draw tail fin (V shape)\n    for d in range(10):\n        x1, y1 = 80 + d, cy - d\n        x2, y2 = 80 + d, cy + d\n        if 0 &lt;= x1 &lt; size and 0 &lt;= y1 &lt; size:\n            img[x1, y1] = 1\n        if 0 &lt;= x2 &lt; size and 0 &lt;= y2 &lt; size:\n            img[x2, y2] = 1\n\n    # Draw dorsal (top) fin\n    for d in range(10):\n        x, y = 40 - d//2, cy - 12 - d\n        if 0 &lt;= x &lt; size and 0 &lt;= y &lt; size:\n            img[x, y] = 1\n\n    # Draw ventral (bottom) fin\n    for d in range(10):\n        x, y = 60 + d//2, cy - 12 - d\n        if 0 &lt;= x &lt; size and 0 &lt;= y &lt; size:\n            img[x, y] = 1\n\n    return img\n\n# Create fixed image (realistic fish skeleton)\nfixed = create_realistic_fish()\n\n# Create moving image with inverted contrast\nmoving = 1 - fixed\n\n# Introduce a misalignment\ndef shift_image(img, dx, dy):\n    return shift(img, shift=(dx, dy), mode='constant', cval=0)\n\nmoving_misaligned = shift_image(moving, 4, 5)\n\n# Define mutual information computation\ndef compute_mi(img1, img2, bins=32):\n    img1_flat = img1.ravel()\n    img2_flat = img2.ravel()\n    c_xy = np.histogram2d(img1_flat, img2_flat, bins=bins)[0]\n    mi = mutual_info_score(None, None, contingency=c_xy)\n    return mi\n\n# Search for best alignment by shifting\ndx_range = np.arange(-10, 11)\ndy_range = np.arange(-10, 11)\nmi_matrix = np.zeros((len(dx_range), len(dy_range)))\n\nfor i, dx in enumerate(dx_range):\n    for j, dy in enumerate(dy_range):\n        shifted = shift_image(moving_misaligned, dx, dy)\n        mi_matrix[i, j] = compute_mi(fixed, shifted)\n\n# Find best shift\nbest_idx = np.unravel_index(np.argmax(mi_matrix), mi_matrix.shape)\nbest_dx = dx_range[best_idx[0]]\nbest_dy = dy_range[best_idx[1]]\n\nprint(f\"Best shift: dx = {best_dx}, dy = {best_dy}\")\n\n# Apply best shift\nmoving_corrected = shift_image(moving_misaligned, best_dx, best_dy)\n\n# Plot\nfig, axs = plt.subplots(2, 2, figsize=(10,10))\n\naxs[0,0].imshow(fixed, cmap='gray')\naxs[0,0].set_title('Fixed Image (Realistic Fish Skeleton)')\n\naxs[0,1].imshow(moving_misaligned, cmap='gray')\naxs[0,1].set_title('Moving Misaligned Image')\n\naxs[1,0].imshow(moving_corrected, cmap='gray')\naxs[1,0].set_title('Moving Corrected Image')\n\ncax = axs[1,1].imshow(mi_matrix, extent=[dy_range[0], dy_range[-1], dx_range[-1], dx_range[0]], cmap='viridis')\naxs[1,1].set_title('Mutual Information Map')\naxs[1,1].set_xlabel('dy')\naxs[1,1].set_ylabel('dx')\nfig.colorbar(cax, ax=axs[1,1])\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#boundary-based-registration",
    "href": "preprocessing.html#boundary-based-registration",
    "title": "4  Preprocessing",
    "section": "Boundary-based registration",
    "text": "Boundary-based registration\n\n\n\n(Greve and Fischl 2009)\n\nCurrently considered best for its purpose and is implemented in fMRIprep. Requires surface reconstruction of the anatomical scan.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#coregistration-result",
    "href": "preprocessing.html#coregistration-result",
    "title": "4  Preprocessing",
    "section": "Coregistration result",
    "text": "Coregistration result\n\n\n\n\n# gambling:\nfile:///home/jovyan/gambling/bids/derivatives/fmriprep/sub-001.html",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#corgistration-before-vs.-after",
    "href": "preprocessing.html#corgistration-before-vs.-after",
    "title": "4  Preprocessing",
    "section": "Corgistration before vs. after",
    "text": "Corgistration before vs. after\n\n\n\n\nstruct -&gt; raw struct -&gt; coreg\n\n\n\n\n\nstruct -&gt; raw struct -&gt; coreg\n\n\n\n\n\nstruct -&gt; raw struct -&gt; coreg\n\n\n\n\n\nstruct -&gt; raw struct -&gt; coreg\n\n\n\n# gambling:\nml freesurfer\nfreeview \\\n/home/jovyan/gambling/bids/sub-001/ses-1/anat/sub-001_ses-1_acq-mprage_T1w.nii.gz \\\n/home/jovyan/gambling/bids/sub-001/ses-1/func/sub-001_ses-1_task-gambling_acq-Fs2_run-1_bold.nii.gz \\\n/home/jovyan/gambling/bids/derivatives/fmriprep/sub-001/ses-1/func/sub-001_ses-1_task-gambling_acq-Fs2_run-1_space-T1w_desc-preproc_bold.nii.gz",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#sec-normalization",
    "href": "preprocessing.html#sec-normalization",
    "title": "4  Preprocessing",
    "section": "Normalization to template space",
    "text": "Normalization to template space\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage source: https://publicdomainreview.org/collection/phrenology-diagrams-from-vaught-s-practical-character-reader-1902/\n\nFinally, if you are preforming a group study, you also need to map each individual subject into some common space. This is not a trivial task. As head shpaes of people are different, there brain shapes are also different. Here I tried to draw the approximate shape if each of these guy’s brains, and some hypothetical template brain.\nNormalization is needed to compensate for individual differences in brain shape for the group analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#talairach-atlas",
    "href": "preprocessing.html#talairach-atlas",
    "title": "4  Preprocessing",
    "section": "Talairach atlas",
    "text": "Talairach atlas\n\n\n\nImage source: Talairach and Tourneux, 1988 (to be confirmed)\n\nNormalization is also needed for a unified coordinate system. You will see that standard coordinates are reported in the articles.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#mni-tamplate",
    "href": "preprocessing.html#mni-tamplate",
    "title": "4  Preprocessing",
    "section": "MNI tamplate",
    "text": "MNI tamplate\n\n\n\nmni_icbm152_t1_tal_nlin_asym_09c\n\n\n\n\nImage source:\nhttps://www.bic.mni.mcgill.ca/ServicesAtlases/ICBM152NLin2009\n\nFurther reading: https://imaging.mrc-cbu.cam.ac.uk/imaging/MniTalairach",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#mapping-to-template",
    "href": "preprocessing.html#mapping-to-template",
    "title": "4  Preprocessing",
    "section": "Mapping to template",
    "text": "Mapping to template\n\n\n\n\n\n\n\n\n\nrigid body\n\n\n\n\n\n\n\naffine\n\n\n\n\n\n\n\nnonlinear (“warp”)\n\n\n\n\n\n\nTo match each of them to the template, it is not enough to coregister them as we did for motion correction, because obviously they are of different sizes. We can add 6 more paraeters to the transform, which compensates does scaling and shearing, to better align them. However, there will still be places wehere they do not align perfectly, because one guy one has a bigger frontal lobe, and gy to a bigger parietal lobe",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#nonlinear-transform",
    "href": "preprocessing.html#nonlinear-transform",
    "title": "4  Preprocessing",
    "section": "Nonlinear transform",
    "text": "Nonlinear transform\n\n\nSo some software packages use a nonlinear warping algorithm to align brains. There you have to estimate a 3D deformation field and then nonlinearly warp each brain onto a template. They are called non-linear, because different parts of the volume are scaled differently.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#normalization-is-done-using-a-structural-scan",
    "href": "preprocessing.html#normalization-is-done-using-a-structural-scan",
    "title": "4  Preprocessing",
    "section": "Normalization is done using a structural scan",
    "text": "Normalization is done using a structural scan\n\n\nThe mapping to common space is usually done via an anatomical scan. First, each subject functional and anatomical scans are coregistered with each other, and then each subject’s anatomical scan is mapped into a template. This is done because the anatomical scan has better quality, and hence the estimated transform is more precise. After you have done that each area in one subject corresponds to the same area in the other subject and you can perform averaging on them.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#volume-based-normalization",
    "href": "preprocessing.html#volume-based-normalization",
    "title": "4  Preprocessing",
    "section": "Volume-based normalization",
    "text": "Volume-based normalization\n\nUnified segmentation\n\n\n\n(Ashburner and Friston 2005)\n\nUnified segmentation is still the best algorithm. It performs bias correction, tissue segmentation and normalization in one step.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#surface-based-registration",
    "href": "preprocessing.html#surface-based-registration",
    "title": "4  Preprocessing",
    "section": "Surface-based registration",
    "text": "Surface-based registration\n\n\nFsaverage: 40 subjects; Align 39 subjects to 1; create an atlas; align 40 subjects to an atlas; re-create atlas; align 40 subject to the atlas; re-create atlas.\nUsing knolwdge from freesurfer recon, each voxel together with it’s time course is maped to one of the 3 atlas spaces: either the left cortical hemisphere, the right hemisphere or the subcrotical structures like the basal ganglia, amygldala, brainstem, etc. And the atlas spaces in this case are fsaverage. After this, the spatial smoothing is done either in 2D or in 3D depending on whether it is a surface space or a volume subcortical space, and voxels that do not belong to the space is being basked out.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#spatial-smoothing",
    "href": "preprocessing.html#spatial-smoothing",
    "title": "4  Preprocessing",
    "section": "Spatial smoothing",
    "text": "Spatial smoothing\n\n\n\n\n\n\n\n\n\noriginal\n\n\n\n\n\n\n\nsmoothed\n\n\n\n\n\n\nFinally, each volume is typically smoothed with a gaussian to increase the signal and supress noise. The amount of smoothing is usally expressed by the shape of the gaussian, which, in turn, is described by it’s full withd at half maximum. Here are the examples of the original volume, the smoothed volume at 5 fwhm and 10 fwhm. You can see that the signal increase happens at the expense of the spatial resolution.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#full-width-at-half-maximum",
    "href": "preprocessing.html#full-width-at-half-maximum",
    "title": "4  Preprocessing",
    "section": "Full width at half maximum",
    "text": "Full width at half maximum\n\n\nCode\n# Load library\nlibrary(ggplot2)\n\n# Define Gaussian function\ngaussian &lt;- function(x, mu = 0, sigma = 1) {\n  (1 / (sigma * sqrt(2 * pi))) * exp(- (x - mu)^2 / (2 * sigma^2))\n}\n\n# Create data\nx &lt;- seq(-5, 5, length.out = 1000)\ny &lt;- gaussian(x, mu = 0, sigma = 1)\n\n# Find half maximum\nymax &lt;- max(y)\nhalf_max &lt;- ymax / 2\n\n# Solve for FWHM points\nleft_idx &lt;- which(y &gt;= half_max)[1]\nright_idx &lt;- tail(which(y &gt;= half_max), 1)\n\nx_left &lt;- x[left_idx]\nx_right &lt;- x[right_idx]\nfwhm_value &lt;- x_right - x_left\n\n# Create data frame\ndata &lt;- data.frame(x = x, y = y)\n\n# Plot\nggplot(data, aes(x, y)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_hline(yintercept = half_max, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = c(x_left, x_right), linetype = \"dotted\", color = \"darkgreen\") +\n  annotate(\"text\", x = 0, y = half_max + 0.02, label = \"Half Maximum\", color = \"red\") +\n  annotate(\"text\", x = x_left - 0.3, y = 0.1, label = sprintf(\"%.2f\", x_left), color = \"darkgreen\") +\n  annotate(\"text\", x = x_right + 0.3, y = 0.1, label = sprintf(\"%.2f\", x_right), color = \"darkgreen\") +\n  annotate(\"text\", x = 0, y = 0.15, label = paste(\"FWHM =\", round(fwhm_value, 2)), color = \"black\", size = 5) +\n  theme_minimal() +\n  labs(title = \"Gaussian Curve with FWHM\",\n       x = \"x\",\n       y = \"Amplitude\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nGaussian curve with FWHM",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#spatial-smoothing-1",
    "href": "preprocessing.html#spatial-smoothing-1",
    "title": "4  Preprocessing",
    "section": "Spatial smoothing",
    "text": "Spatial smoothing\n\n\n\n\n\n\n\n\n\noriginal\n\n\n\n\n\n\n\n5 mm FWHM\n\n\n\n\n\n\n\n10 mm FWHM\n\n\n\n\n\n\nPurpose1: increase the signal and suppress the noise\nPurpose2: even better compensate for inter-individual differences\nFMRIprep does not smooth the data",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#critique",
    "href": "preprocessing.html#critique",
    "title": "4  Preprocessing",
    "section": "Critique",
    "text": "Critique\n\n(Stelzer et al. 2014)\n\nVolume smoothing has been heavily criticized by some influential people in the field. It has even been called “deficient approaches to human neuroimaging”. Because it does not only degrade the resolution, but also decreases the effect size. But it is still being done in many cases – it all depends on the questions you are asking",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#surface-based-smoothing",
    "href": "preprocessing.html#surface-based-smoothing",
    "title": "4  Preprocessing",
    "section": "Surface-based smoothing",
    "text": "Surface-based smoothing\n\n\n\nslide courtesy of Doug Greve\n\n5 mm apart in 3D\n25 mm apart on surface\nAveraging with other tissue types (WM, CSF)\nAveraging with other functional areas\nOne important feature is that fsfast allows surface-based processing, and therefore overcomes some of the difficulties caused by smoothing.\nHere is an example of how it works. Here is a piece of freesrurfer reconstructed cortical surface with yellow a white matter surface and red the the gray matter surface. The two points, on opposite banks of the sulcus, are only 5 mm apart in the volume, however, they are very far from each other on the surface. So these two points can be two completely different functional areas. However, if you smooth on the volume, as shown here, you will mix them together. Surface smoothing routines use the information from the freesurfer’s surface reconstruction and smoothe the data along the cortical surface. This allows to take advantage of smoothing procedure without mixing these two areas together.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#fmriprep-1",
    "href": "preprocessing.html#fmriprep-1",
    "title": "4  Preprocessing",
    "section": "fMRIprep",
    "text": "fMRIprep\n\n\n\nPros\n\nUseful for processing many subjects, whole-brain data, standard acquisition protocols\nCollection of best practices from all software\nHPC compatibility\nUseful for “users” when knowledgeable people assist them\nAutomatic quality control\nIncreases reproducibility (?)\n\n\n\n\nCons\n\nDifficult/impossible to use for custom acquisitions\nDifficult/impossible to manually intervene\nMay not be worth it with few subjects are being processed\nRequires a Linux environment and corresponding knowledge\nNeed integration with the software you will use for your analysis\nHard to explain what you did (black box)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#example-i",
    "href": "preprocessing.html#example-i",
    "title": "4  Preprocessing",
    "section": "Example I",
    "text": "Example I\n\n\n\n(Arsenovic, Ischebeck, and Zaretskaya 2022)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#example-ii",
    "href": "preprocessing.html#example-ii",
    "title": "4  Preprocessing",
    "section": "Example II",
    "text": "Example II\n\n\n\n(Coates et al. 2024)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#run-fmriprep",
    "href": "preprocessing.html#run-fmriprep",
    "title": "4  Preprocessing",
    "section": "Run fMRIprep",
    "text": "Run fMRIprep\nBefore running\n\nApply for a freesurfer license file with your Uni Graz email address: https://surfer.nmr.mgh.harvard.edu/registration.html\nDownload it and store in /home/jovyan/license.txt (or wherever you like, but make sure you adapt the path in the fMRIprep command below)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#start-fmriprep-from-neurodesktop",
    "href": "preprocessing.html#start-fmriprep-from-neurodesktop",
    "title": "4  Preprocessing",
    "section": "Start fMRIprep from neurodesktop",
    "text": "Start fMRIprep from neurodesktop",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#terminal-window",
    "href": "preprocessing.html#terminal-window",
    "title": "4  Preprocessing",
    "section": "Terminal window",
    "text": "Terminal window\n# create freesurfer subject directory\nmkdir -p /home/jovyan/gambling/bids/derivatives/fmriprep/sourcedata/freesurfer/\n\n# define the path to the freesurfer subject directory\nSUBJECTS_DIR=/home/jovyan/gambling/bids/derivatives/fmriprep/sourcedata/freesurfer/\n\n# run fMRIprep with 4 output spaces: T1 native, MNI, fsnative, fsaverage\nfmriprep /home/jovyan/gambling/bids/ /home/jovyan/gambling/bids/derivatives/fmriprep/ \\\nparticipant \\\n--fs-license-file /home/jovyan/license.txt \\\n--output-spaces T1w MNI152NLin2009cAsym fsnative fsaverage \nAfter this, fMRIprep will run for 4 hours. You do not need to wait for 4 hours! Close neurodesktop and log out. fMRIprep will run in the background. When you come back the next day, everything should be as you left it, with fMRIprep being done. Inspect the html output and submit a screenshot to moodle.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#output-spaces",
    "href": "preprocessing.html#output-spaces",
    "title": "4  Preprocessing",
    "section": "Output spaces",
    "text": "Output spaces\n``` {{bash}}\ncd /home/jovyan/gambling/bids/derivatives/fmriprep/sub-001/ses-1/func/\nls -l *_bold.nii.gz\n```\n\n``` {{bash}}\ncd /home/jovyan/gambling/bids/derivatives/fmriprep/sub-001/ses-1/func/\nls -l *_bold.func.gii\n```",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#html-report",
    "href": "preprocessing.html#html-report",
    "title": "4  Preprocessing",
    "section": "HTML report",
    "text": "HTML report\n\nfile:///home/jovyan/gambling/bids/derivatives/fmriprep/sub-001.html",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#boilerplate",
    "href": "preprocessing.html#boilerplate",
    "title": "4  Preprocessing",
    "section": "Boilerplate",
    "text": "Boilerplate",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "preprocessing.html#references",
    "href": "preprocessing.html#references",
    "title": "4  Preprocessing",
    "section": "References",
    "text": "References\n\n\n\n\nArsenovic, Ana, Anja Ischebeck, and Natalia Zaretskaya. 2022. “Dissociation Between Attention-Dependent and Spatially Specific Illusory Shape Responses Within the Topographic Areas of the Posterior Parietal Cortex.” The Journal of Neuroscience, September. https://doi.org/10.1523/JNEUROSCI.0723-22.2022.\n\n\nAshburner, John, and Karl J Friston. 2005. “Unified Segmentation.” NeuroImage 26 (3): 839–51. https://doi.org/10.1016/j.neuroimage.2005.02.018.\n\n\nCoates, Adam, David Linhardt, Christian Windischberger, Anja Ischebeck, and Natalia Zaretskaya. 2024. “High-Resolution 7T fMRI Reveals the Visual Zone of the Human Claustrum.” Imaging Neuroscience 2 (October): 1–15. https://doi.org/10.1162/imag_a_00327.\n\n\nEsteban, Oscar, Christopher J. Markiewicz, Ross W. Blair, Craig A. Moodie, A. Ilkay Isik, Asier Erramuzpe, James D. Kent, et al. 2018. “fMRIPrep: A Robust Preprocessing Pipeline for Functional MRI.” Nature Methods 16 (1): 111–16. https://doi.org/10.1038/s41592-018-0235-4.\n\n\nGreve, Douglas N., and Bruce Fischl. 2009. “Accurate and Robust Brain Image Alignment Using Boundary-Based Registration.” NeuroImage 48 (1): 63–72. https://doi.org/10.1016/j.neuroimage.2009.06.060.\n\n\nStelzer, Johannes, Gabriele Lohmann, Karsten Mueller, Tilo Buschmann, and Robert Turner. 2014. “Deficient Approaches to Human Neuroimaging.” Frontiers in Human Neuroscience 8 (July). https://doi.org/10.3389/fnhum.2014.00462.\n\n\nTierney, Tim M., Nicholas A. Alexander, Nicole Labra Avila, Yael Balbastre, Gareth Barnes, Yulia Bezsudnova, Mikael Brudfors, et al. 2025. “SPM 25: Open Source Neuroimaging Analysis Software.” https://doi.org/10.48550/ARXIV.2501.12081.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preprocessing</span>"
    ]
  },
  {
    "objectID": "glm.html",
    "href": "glm.html",
    "title": "5  General linear model analysis",
    "section": "",
    "text": "Analysis phases\nof fMRI data",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>General linear model analysis</span>"
    ]
  },
  {
    "objectID": "glm.html#analysis-phases",
    "href": "glm.html#analysis-phases",
    "title": "5  General linear model analysis",
    "section": "",
    "text": "Single-subject - first level - fixed effects analysis (FFX)\nGroup - second-level - random effects analysis (RFX)\n\n\nThis is equivalent to e.g. conducting many trials per subject to measure reaction time, and then compute a subject-specific mean per condition, after which you would perform the actual statistical inference\nMultilevel modelling is also possible (for small datasets), but less frequent.\n\n\n\nFor a general overviewo of basic GLM analysis, see Introduction to fMRI",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>General linear model analysis</span>"
    ]
  },
  {
    "objectID": "glm.html#before-analysis",
    "href": "glm.html#before-analysis",
    "title": "5  General linear model analysis",
    "section": "Before analysis",
    "text": "Before analysis\n\nPick your analysis space\nDecide whether/how/how much to smooth the data",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>General linear model analysis</span>"
    ]
  },
  {
    "objectID": "glm.html#software",
    "href": "glm.html#software",
    "title": "5  General linear model analysis",
    "section": "Software",
    "text": "Software\n\n\n\n\n\n\n\n\n\nSince 1994 http://www.fil.ion.ucl.ac.uk/spm/\n\n\n\n\n\n\n\nSince 1994 http://afni.nimh.nih.gov/afni/\n\n\n\n\n\n\n\n\n\nSince 2000 http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/\n\n\n\n\n\n\n\nSince 1999 https://freesurfer.net/\n\n\n\n\n\n\nPreprocessing used to be integrated into the software used for the actual analysis. And there are many software for this. On this slide I just put a few of them. Each of them has a slightly different phylosophy behind it, but all of them do roughly the same thing, so at the end it should not matter much which of them you use.\nOne of the oldest ones are:\n\nSPM – statistical parameteric mapping from UCL. It is a free MATLAB-based toolbox. However, it depends on the MATLAB licence, and has not been updated for a long time. The new update just came out which spans the gab from 2012 to 2025 (Tierney et al. 2025).\nAFNI - from NIH\nFSL from Oxford – a set of linux tools, also free and independent of MATLAB, which is an advantage, but requires Linux.\nFreeSurfer/FSFAST form the Martinos center - it is Linux based, and was originally conceived as a tool for structural data analysis, but has an fMRI module\n\nHistorical software\n\nbroccolli, that can utilize GPU computing and can process the same dataset n times faster\n\nWith the awareness of open science, and with the trend towards reproducibility and transparency, and with the release of fMRIprep software, the preprocessing got detached from the actual data analysis.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>General linear model analysis</span>"
    ]
  },
  {
    "objectID": "glm.html#nilearn",
    "href": "glm.html#nilearn",
    "title": "5  General linear model analysis",
    "section": "Nilearn",
    "text": "Nilearn\n\n\n\nhttps://nilearn.github.io/stable/index.html",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>General linear model analysis</span>"
    ]
  },
  {
    "objectID": "glm.html#ingredients",
    "href": "glm.html#ingredients",
    "title": "5  General linear model analysis",
    "section": "Ingredients",
    "text": "Ingredients\n\nfMRIprep output\nevents files in bids format, located in the same directory as the raw functional data\n\nyou can copy them to your folder with the following terminal command\nrsync -a -v /shared/2025_SS_SE_ANI/gambling/tsv_behr_data /home/jovyan/gambling/\nA zip archive is also attached to the moodle assigment",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>General linear model analysis</span>"
    ]
  },
  {
    "objectID": "glm.html#install-nilearn",
    "href": "glm.html#install-nilearn",
    "title": "5  General linear model analysis",
    "section": "Install nilearn",
    "text": "Install nilearn\nOpen the terminal window\n\ntype:\npip install nilearn\nand wait until the installation finishes",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>General linear model analysis</span>"
    ]
  },
  {
    "objectID": "glm.html#run-the-analysis",
    "href": "glm.html#run-the-analysis",
    "title": "5  General linear model analysis",
    "section": "Run the analysis",
    "text": "Run the analysis\n\nOpen the jupyter notebook nilearn_ffix_volume.ipynb\n\nyou can copy it with the following terminal command\nrsync -a -v /shared/2025_SS_SE_ANI/gambling/nilearn_ffx_volume.ipynb /home/jovyan/gambling/\na copy is also attached to the moodle assignment\n\ntry to run the analysis in the MNI space\n\nFeel free to play around with the parameters and visualization options",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>General linear model analysis</span>"
    ]
  },
  {
    "objectID": "glm.html#references",
    "href": "glm.html#references",
    "title": "5  General linear model analysis",
    "section": "References",
    "text": "References\n\n\n\n\nTierney, Tim M., Nicholas A. Alexander, Nicole Labra Avila, Yael Balbastre, Gareth Barnes, Yulia Bezsudnova, Mikael Brudfors, et al. 2025. “SPM 25: Open Source Neuroimaging Analysis Software.” https://doi.org/10.48550/ARXIV.2501.12081.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>General linear model analysis</span>"
    ]
  },
  {
    "objectID": "mcc.html",
    "href": "mcc.html",
    "title": "6  Multiple comparison correction",
    "section": "",
    "text": "Reminder: group analysis\nIn whole-brain analysis",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple comparison correction</span>"
    ]
  },
  {
    "objectID": "mcc.html#family-wise-error-rate",
    "href": "mcc.html#family-wise-error-rate",
    "title": "6  Multiple comparison correction",
    "section": "Family-wise error rate",
    "text": "Family-wise error rate\n\n\n\nImage credit: unknown\n\nIf the data is not smoothed, equivalent to bonferroni",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple comparison correction</span>"
    ]
  },
  {
    "objectID": "mcc.html#other-correction-types",
    "href": "mcc.html#other-correction-types",
    "title": "6  Multiple comparison correction",
    "section": "Other correction types",
    "text": "Other correction types\n\nCluster threshold\n\n\nFalse discovery rate\n\n\nCluster-level inference",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple comparison correction</span>"
    ]
  },
  {
    "objectID": "mcc.html#uncorrected",
    "href": "mcc.html#uncorrected",
    "title": "6  Multiple comparison correction",
    "section": "Uncorrected",
    "text": "Uncorrected\n\n\n# interactive plot (you can browse the activations)\nfrom nilearn import plotting\n\n# Use subject's anatomy as background\nbg_img = '/home/jovyan/gambling/bids/derivatives/fmriprep/sub-001/ses-1/anat/sub-001_ses-1_acq-mprage_desc-preproc_T1w.nii.gz'\nplotting.view_img(zmap, threshold=1.96, vmax=10, \n    bg_img=bg_img,\n    cut_coords=[0, 0, 0],\n    width_view=600,\n    title=contrast_string)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple comparison correction</span>"
    ]
  },
  {
    "objectID": "mcc.html#cluster-thresholded",
    "href": "mcc.html#cluster-thresholded",
    "title": "6  Multiple comparison correction",
    "section": "Cluster-thresholded",
    "text": "Cluster-thresholded\n\n\nfrom nilearn.glm import threshold_stats_img\n\nthresholded_map1, threshold1 = threshold_stats_img(\n    zmap,\n    alpha=0.05,\n    height_control=\"fpr\",\n    cluster_threshold = 100,\n    two_sided=True,\n)\n\n# Use subject's anatomy as background\nbg_img = '/home/jovyan/gambling/bids/derivatives/fmriprep/sub-001/ses-1/anat/sub-001_ses-1_acq-mprage_desc-preproc_T1w.nii.gz'\nplotting.view_img(thresholded_map1, threshold=threshold1, vmax=10, \n    bg_img=bg_img,\n    cut_coords=[0, 0, 0],\n    width_view=600,\n    title=contrast_string)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple comparison correction</span>"
    ]
  },
  {
    "objectID": "mcc.html#fdr-thresholded",
    "href": "mcc.html#fdr-thresholded",
    "title": "6  Multiple comparison correction",
    "section": "FDR-thresholded",
    "text": "FDR-thresholded\n\n\nfrom nilearn.glm import threshold_stats_img\n\nthresholded_map1, threshold1 = threshold_stats_img(\n    zmap,\n    alpha=0.05,\n    height_control=\"fdr\",\n    two_sided=True,\n)\n\n# Use subject's anatomy as background\nbg_img = '/home/jovyan/gambling/bids/derivatives/fmriprep/sub-001/ses-1/anat/sub-001_ses-1_acq-mprage_desc-preproc_T1w.nii.gz'\nplotting.view_img(thresholded_map1, threshold=threshold1, vmax=10, \n    bg_img=bg_img,\n    cut_coords=[0, 0, 0],\n    width_view=600,\n    title=contrast_string)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple comparison correction</span>"
    ]
  },
  {
    "objectID": "mcc.html#fwe-thresholded",
    "href": "mcc.html#fwe-thresholded",
    "title": "6  Multiple comparison correction",
    "section": "FWE-thresholded",
    "text": "FWE-thresholded\n\n\nfrom nilearn.glm import threshold_stats_img\n\nthresholded_map1, threshold1 = threshold_stats_img(\n    zmap,\n    alpha=0.05,\n    height_control=\"bonferroni\",\n    two_sided=True,\n)\n\n# Use subject's anatomy as background\nbg_img = '/home/jovyan/gambling/bids/derivatives/fmriprep/sub-001/ses-1/anat/sub-001_ses-1_acq-mprage_desc-preproc_T1w.nii.gz'\nplotting.view_img(thresholded_map1, threshold=threshold1, vmax=10, \n    bg_img=bg_img,\n    cut_coords=[0, 0, 0],\n    width_view=600,\n    title=contrast_string)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple comparison correction</span>"
    ]
  },
  {
    "objectID": "mcc.html#non-parametric-inference",
    "href": "mcc.html#non-parametric-inference",
    "title": "6  Multiple comparison correction",
    "section": "Non-parametric inference",
    "text": "Non-parametric inference\n\nPermutation-based inference\n\n\n\n\n\n\n\n\n\n(Nichols and Holmes 2001)\n\nFor the multiple comparison case, we use the same logic, but instead of single voxel we consider the maximum of each statistical map.\n\n\n\n\n\nNichols, Thomas E., and Andrew P. Holmes. 2001. “Nonparametric Permutation Tests for Functional Neuroimaging: A Primer with Examples.” Human Brain Mapping 15 (1): 1–25. https://doi.org/10.1002/hbm.1058.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multiple comparison correction</span>"
    ]
  }
]