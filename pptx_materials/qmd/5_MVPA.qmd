## Multivariate fMRI

aka MVPA, aka SVM

::: {.notes}

:::

## A typical experiment

TR

20 s on

20 s off

![Slide Image](images/slide_2_img.png)

![Slide Image](images/slide_2_img.png)

![Slide Image](images/slide_2_img.png)

![Slide Image](images/slide_2_img.png)

::: {.notes}
To help us better understand the analysis steps, let’s use an example.
Let’s say we have conducted a calssical experiment in the visual system, a flickerign checkerboard.
In this experiment, we want to find out which brain areas are active when subjects view a flickering checkerboard compared to when they view a gray background.
We have shown to every volunteer a checkerboard for e.g. 20 second interleaved with a 20 s rest, and we will measure a whole brain volume every 2 seconds, for e.g. to minutes or so.


Matlab code to generate stimulus, BOLD and shifted BOLDX = [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0];
bf = spm_get_bf; % indicated a tr of 2.5
Y = conv(X,bf.bf);
Ye = Y+randn(size(Y)).*0.2;
:::

## A typical research question

Which areas are activated by flickering checkerboard?

::: {.notes}

:::

## 4D functional dataset

time

3D

Repetition time (TR)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

![Slide Image](images/slide_4_img.png)

::: {.notes}
And, in a functional experiment we usually measure brain activity across the whole volume over extended perionds of time, so it is comfortalbe to think about each functional dataset that we acquire as a 4D dataset, which consists of 3D brain volumes and time as a 4th dimension
:::

## fMRI analysis

::: {.notes}

:::

## Single-subject (first-level) analysis

Univariate/voxel-wise analysis

Question: Which areas are activated by the flickering checkerboard?

![Slide Image](images/slide_6_img.png)

::: {.notes}
Remember that an image is 4d and consists of little 3d cubes called voxels, with the 4th diemtion being time.
A calssical analysis is done over tiem for every voxel in the brain independelty
:::

## Checkerboard experiment

![Slide Image](images/slide_7_img.png)

![Slide Image](images/slide_7_img.png)

::: {.notes}
Let’s recall our checkerboard experiment where particients viewed either a checkerboard or a gray screen. Let’s also creata a function, called the stimulsu function, which is one where the checkerboard was on, and zero where the checkerboard was off
:::

## Checkerboard experiment

![Slide Image](images/slide_8_img.png)

![Slide Image](images/slide_8_img.png)

::: {.notes}
Let’s now look at the time course of a voxel in the visual coretx. You see that it is noisy and delayed, but it kind of follows the stimulus.
:::

## General Linear Model (GLM)

::: {.notes}
However, there is a better way called the General linear model (shortly called glm)
It boils down to making a prediction about the signal time course and comparing this prediction with the measured signal
:::

## Building regressors

convolution

::: {.notes}
How can we build a prediction about the signal?
Well, we know the timing of the stimulus on the screen – called the stimulus function, and we know a tiypical shape of the hemodynamic response.
The signal prediction, called a regressor, is creased by the convolution operation between the stimulus function and the HRF.
The result of this convolution is will look like this:

Since we know aaproximately what a signal should look like – It is our hemodynamic response function. By convolution of the stimulus function with hrf we can generate a signal predictor, which is called a regressor.
Then we fit the regressor to the measured signal. If it fits nicely there is an activation. How we decide if it fits nicely?
:::

## Building regressors

convolution

::: {.notes}
Now we fit our prediction to the data (shown in read). If it fits nicely there is an activation. How we decide if it fits nicely?
:::

## General Linear Model

Y(t) =  β * X(t)  +  c  +  e(t)

Measured data

Modeled data (regressors)

Constant offset

Error (e.g. noise, confounds)

::: {.notes}
How do we know that it fits nicely?
Using a least square estimation of a linear regression, called the genral linear model (GLM)
The assumption behind glm is that you signal Y consists of a sum of the folloing terms:
Modelled response (regressor)
Constant offset (which is not so important)
And some residual error (scanner noise, confounds, etc)
Where beta term, aslo called the beta weight,  reflects how well your model fits the data.
:::

## General linear model fit

![Slide Image](images/slide_13_img.png)

::: {.notes}

:::

## Statistical inference (t-test) in GLM

t = β/SE(β)

Thresholding:
deal with the multiple comparison problem!

72,221 voxels

![Slide Image](images/slide_14_img.png)

![Slide Image](images/slide_14_img.png)

![Slide Image](images/slide_14_img.png)

::: {.notes}
How do we get from beta estimates to making statistical inference? Rejecting the null hypothesis? 
The good thing is that beta estimated devided by its standard eroor is a t-statistic with a t-distribution. So to know wheter an activation in one voxel is significant is relatively straifhtforward.
If we had just one voxel, we would have computed the t-statistic, and then depending on the degrees of freedom determined if it exceeds the critical value. 
However, we are doing the same statistical test for MANY voxels. SO the probability that we find a significant voxel simply by chance increases. This is the multiple comparison problem that is encountered anywhere in statistics. In fMRI it is particularly prominent, because the number if singe tests is enormous. 
There are several ways and philosophies for dealign with it, I won’t go into details right now. The important thing is that any voxel wise analysis MUST deal with this problem in some way.
:::

## Multiple comparisons correction

![Slide Image](images/slide_15_img.png)

![Slide Image](images/slide_15_img.png)

::: {.notes}

:::

## What about two conditions? Checkerboard vs. Cola

Condition A

Condition B

![Slide Image](images/slide_16_img.png)

::: {.notes}

:::

## General Linear Model

Y(t) =  β1 * X1(t)  + β2 * X2(t) +  c  +  e(t)

Measured data

Modeled data (regressor 1)

Error (e.g. noise, confounds)

Modeled data (regressor 2)

::: {.notes}
How do we know that it fits nicely?
Using a least square estimation of a linear regression, called the genral linear model (GLM)
The assumption behind glm is that you signal Y consists of a sum of the folloing terms:
Modelled response (regressor)
Constant offset (which is not so important)
And some residual error (scanner noise, confounds, etc)
Where beta term, aslo called the beta weight,  reflects how well your model fits the data.
:::

## Statistical inference (t-test) in GLM

Thresholding:
deal with multiple comparison problem!

72,221 voxels

t = (β1 – β2) / SE(β1;β2)

![Slide Image](images/slide_18_img.png)

![Slide Image](images/slide_18_img.png)

![Slide Image](images/slide_18_img.png)

::: {.notes}
How do we get from beta estimates to making statistical inference? Rejecting the null hypothesis? 
The good thing is that beta estimated devided by its standard eroor is a t-statistic with a t-distribution. So to know wheter an activation in one voxel is significant is relatively straifhtforward.
If we had just one voxel, we would have computed the t-statistic, and then depending on the degrees of freedom determined if it exceeds the critical value. 
However, we are doing the same statistical test for MANY voxels. SO the probability that we find a significant voxel simply by chance increases. This is the multiple comparison problem that is encountered anywhere in statistics. In fMRI it is particularly prominent, because the number if singe tests is enormous. 
There are several ways and philosophies for dealign with it, I won’t go into details right now. The important thing is that any voxel wise analysis MUST deal with this problem in some way.
:::

## What about X conditions?Design Matrix

time

regressors

::: {.notes}
In principle, you can have as many regressors as you like; some of them will be you experimental conditions; some of them will be confound regressors, the so-called “nuisance regressors”. 
They all comprize a matrix called the design matrix. 
Here I have taken the most complex design matrix I could find in with google, I think it contains around 70 regressors. 
They are located along the colums. Along the rows we have a time dimenstion. After the glm fit each of these regressors will have a beta estimate. 
This offers a lot of flexibility about what you can do with beta estimates.
:::

## Contrast: linear combination of betas

Contrast vector: describes how beta-estimates are combined (“weighted”)

Contrast image: a 3D volume containing the result of beta-combinations

::: {.notes}
An inportant term in the general linear model analysis is contrast. 
Contrast is just the linear combination of bete estimates that you are interested in.
In our example we have compared tow beta estimates, and the contrast was 1 -1 0
but you can test the statistical significance of more complex combinations of beta estimates.

The way in which you combine the beta estimates is described by a verctor called contrast vector.
After you have combined the beta estimates according to the contrast vector, you get a contrast image – which is a 3D volume in which every voxel contains a result of beta combinations.
:::

## Group analysis (second-level analysis)

Subject 1 contrast image

Subject 2 contrast image

Subject n contrast image

Thresholding:
deal with multiple comparison problem!

Is our combination of betas different from zero?

![Slide Image](images/slide_21_img.png)

![Slide Image](images/slide_21_img.png)

::: {.notes}
When we have the contrast images we are interested in, i.e. gocnigionon A vs condition B, we are ready for the gorup analysis.
Typically, you combute one contrast image per subject which corresponds to your hypothesis. Then you use the contrast images to do a one – sample t-test. It tests whether your contrast image is significantly different form zero.
After you’ve computed a one-sample t-test for every voxel, the procedue is the same as for the individual analysis; you need to threshold the image accounting for the multiple comparison problem.
:::

## GLM advantages

Complex experimental designs
“Regress out” uninteresting effects/confounds
Estimate HRF shape

?

::: {.notes}
A GLM has approach has several advantages over the simple binning of data.
:::

## Multivariate analysis: Cola vs. Pepsi

Condition A

Condition B

![Slide Image](images/slide_23_img.png)

::: {.notes}

:::

## A widely used method in neuroscience

fMRI
EEG
MEG
Single-cell recordings
Etc., etc.

Analysis of multiple dependent variables (brain signals) simultaneously

::: {.notes}

:::

## First MVPA paper

Haxby et al., Science 2001

::: {.notes}

:::

## First MVPA paper

Haxby et al., Science 2001

Representational similarity analysis (RSA)

::: {.notes}

:::

## Main principle: two runs, 3 voxels

Run 2 activity

Run 1 activity

2

faces

houses

1

3

Faces response

Voxel #

1

3

2

::: {.notes}

:::

## Main principle: two runs, 3 voxels

Run 2 activity

Run 1 activity

2

faces

houses

2

1

1

3

3

Faces response

Voxel #

1

3

2

Houses response

1

3

2

Voxel #

::: {.notes}

:::

## First SVM paper(s): year 2005

adapted from Kandel et al., Principles of Neuroscience 2000

Orientation column signal: < 1 mm spatial frequency

![Slide Image](images/slide_29_img.png)

::: {.notes}

:::

## Main principle: 2D

https://eight2late.wordpress.com/2017/02/07/a-gentle-introduction-to-support-vector-machines-using-r/

Electrode 2
Voxel 2
Time point 2
Neuron 2

Electrode 1
Voxel 1
Time point 1
Neuron 1

::: {.notes}

:::

## Main principle

https://eight2late.wordpress.com/2017/02/07/a-gentle-introduction-to-support-vector-machines-using-r/

Electrode 2
Voxel 2
Time point 2
Neuron 2

Electrode 1
Voxel 1
Time point 1
Neuron 1

::: {.notes}

:::

## Main principle

https://en.wikipedia.org/wiki/Support-vector_machine

Electrode 2
Voxel 2
Time point 2
Neuron 2

Electrode 1
Voxel 1
Time point 1
Neuron 1

::: {.notes}

:::

## Why do classifiers work?

adapted from Kandel et al., Principles of Neuroscience 2000

Orientation column signal: < 1 mm spatial frequency

![Slide Image](images/slide_33_img.png)

::: {.notes}

:::

## In this course: human ocular dominance columns

Kandel et al., 2000

::: {.notes}
Noch viel wichtiger fuer NeurowissenschaftlerInnen ist es, die Aktivitaet von diesen keinen Strukturen innerhalb der Hirnrinde messen zu koennen. Es gibt einige Beispiele. Ich werde von den Augendominanzsaulen sprechen, mit dennen ich persoenlich zu tun hatte. 
Was sind die Augendominanzsaulien? Das sind Bereiche im primaren visuellen Areal, die die information nur von einem der beiden Augen bekommen. In diesem Beispiel gelb von dem linken Auge, lilla von dem rechten Auge. Diese Information wird spaeter im Gehirn zusammengefueft, um scharferes sehen und vor allem die Tiefenwahrnehmung zu ermoeglichen. Aber before das passiert, bleibt die Information der beiden Augen getrennt.
:::

## Amblyopia

::: {.notes}
Warum sind die Augendominanzsauelen so wichtig? Man glaubt, dass deren Entwicklung und deren Aktivitaet zum Beispiel mit Amblyopie (oder Schwachsichtigkeit) zu tun hat. Sie kennen wahrscheinlich kleine Kinder, die auf einem Auge ein Pflaster haben? Das ist die uebliche Therapie fuer Amblyopie, die versucht, das Auge, das nicht vollstaendig benutzt wird, zum Sehen zu zwingen.
Diese Therapie ist leider nicht ganz effizient,  und viele Leute, die in der Kindheit Schwachsichtigkeit hatten, haben das auch im Erwachsenalter. Sie koennen keine 3D movies schauen und schielen. Wir muessen viel mehr ueber die Informationverarbeitung von beiden Augen, und ueber Augendominanzsauelen verstehen, um das effizienter behandeln zu koennen.
:::

## Adams et al., 2007

![Slide Image](images/slide_36_img.png)

![Slide Image](images/slide_36_img.png)

![Slide Image](images/slide_36_img.png)

::: {.notes}
Bis vor kurzem war die Untersuchung von Augendominanzsaueln bem Mensch nur post morten moeglich. Wie wurde es gemacht? Man hat bei Menschen, die nur ein Auge hatten, nach ihrem Tod  das Gehirn entfernt. Zuerst wurde der Occipitallappen abgeschnitten, wo sich die visuellen Arealen befinden. Dann wurde die graue Substanz – also die Hirnrinde der visuellen Bereiche – abgetrennt und geglaettet, damit man zwischen den Hirnwindugen besser sieht.
Hier ist der Bereich markiert, woe die Augendominanzsauelen auftretten sollen.
:::

## Untitled Slide

![Slide Image](images/slide_37_img.png)

::: {.notes}
Danach wurde die glatte Hirnrinde mit einer speziellen Substanz gefaerbt, die nur die Bereiche faerbt, die wahrend des Lebens aktiv waren – die von dem gesunden Auge. Dadurch konnte man die Augendominanzsaulen auf der Oberflaeche sehen. Von der Oberflaeche gesehen haben sie so ein typeisches Leopartdemuster.
Ziemlich aufwending, nicht wahr?
:::

## fMRT - Experiment

![Slide Image](images/slide_38_img.png)

::: {.notes}
Schoen langsam koennen wir mit modernen Technologien das gleiche beim lebenden Menschen beobachten.
Was wir brauchen ist ein Hochfeldscanner, der uns eine hohe Aufloesung ermoeglicht.
Wir nehmen einen gesunden Probanden und schieben ihn oder sie in den Scnaner hinein. Im Scanner ist ein Bildschirm, auf dem man dynamische Bilder zeigen kann, die die visuellen Areale aktivieren.
:::

## fMRT - Experiment

![Slide Image](images/slide_39_img.png)

::: {.notes}
Wenn man das gleiche Bild zuerst nur durch das linke Auge
:::

## fMRT - Experiment

![Slide Image](images/slide_40_img.png)

::: {.notes}
Und dann nur durch das rechte Auge Zeigt, kann man die ensrpechenden Augendominanzsauelen aktivieren.
:::

## Untitled Slide

![Slide Image](images/slide_41_img.png)

::: {.notes}
Ein kleines Problem gibt es noch. Durch die Hirnwindugen sieht man das typische Augendominanzmuster leider nicht so gut.
:::

## Untitled Slide

![Slide Image](images/slide_42_img.png)

![Slide Image](images/slide_42_img.png)

![Slide Image](images/slide_42_img.png)

::: {.notes}
Darum nehmen wir ein anatomisches Bild, und generieren mittels spezieller Software ein Modell der Hirnoberflaeche. Hier sieht man es in Gelb. Innen ist die Grenze zwischen der grauen und der wissen Substanz, aussen ist die Grenze zwischen der grauen Substanz und der Hirnflussigkeit.
:::

## Untitled Slide

![Slide Image](images/slide_43_img.png)

![Slide Image](images/slide_43_img.png)

::: {.notes}
Wir nehmen dieses 3-Dimentionale Modell, und beginnen, es mittels eines speziellen Komputerprogramms zu glaetten.  Dieses kleine Video zeigt Ihnen den Ablauf.
Als Ergebniss haben wir dann eine flache Gehirnhaelfte ohne Hirnwindungen. In Gelb ist eine Region markiert, wo die Augendominanzsaulen zu sehen sind.
:::

## Ocular dominance columns in vivo

Zaretskaya et al., 2020

![Slide Image](images/slide_44_img.png)

![Slide Image](images/slide_44_img.png)

::: {.notes}
Und hier ist schon mal das ergebniss eines Experiments. 
Zum Vergleich haben wir das Experiment zuerst mit einem typischen 3 Tesla Scanner gemacht, der nur eine sehr maessige Aufloesung ermoeglicht. Sieht man hier im gelben Bereich irgendwas, was wie Augendominanzsauelen ausschaut? Eher nicht oder wenig. Man sieht rote Punkte, die hier das linke Auge räpresentieren und blaue Punkte, die das rechte Auge räpräsentieren, sowohl innerhalb als auch ausserhalb.
:::

## Augendominanzsäulen in vivo

Zaretskaya et al., 2020

![Slide Image](images/slide_45_img.png)

![Slide Image](images/slide_45_img.png)

::: {.notes}
Und hier, zum vergleichen, ist das gleiche Experiment, aber mittels Hochfeldscanner, mit einer viel hoeheren Aufloesung durchgefuehrt. Ich hoffe, sie stimmen mir zu, dass viel mehr gelb und blau im pimaeren visuellen Areal zu finden sind, und dass das Bild unserem Leoparden-Muster ähnlich wird.
:::

## 3x3x3 mm

::: {.notes}
Fuer diejenigen, die nicht ueberzeugt sind, muss ich noch etwas sagen. 
So toll wie post mortem koenenn wir die Sualen noch nicht sehen. Das ist deshalb so, weil die Dicke einer Saule ungefahr 0.8 mm ist, und unsere Aufloesung ist auch 0.8 mm. Deshalb werden wir in den Pixel auf dem Bild, die zur haelfte das linke Auge und zur haelfte das rechte Auge enthalten, nichts finden. Aber die Technologie entwickelt sich rasch, und es wird nicht mehr lange dauren, bist unsere Ergebnisse der Qualitet von post mortem Daten entsprechen.
:::

## In this course

Project 6.1: Can we detect ocular dominance signal with representational similarity analysis?
Project 6.2: Can we detect (decode) ocular dominance signal with SVM?

::: {.notes}

:::

