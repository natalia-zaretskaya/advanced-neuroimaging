## Resting-state fMRI

1

::: {.notes}

:::

## Resting-state fMRI

DMN

Functional connectivity

2

Raichle et al., PNAS 2001

Fox et al., PNAS 2005

::: {.notes}

:::

## Checkerboard experiment

![Slide Image](images/slide_3_img.png)

![Slide Image](images/slide_3_img.png)

::: {.notes}
Let’s now look at the time course of a voxel in the visual coretx. You see that it is noisy and delayed, but it kind of follows the stimulus.
:::

## Resting-state fluctuation

![Slide Image](images/slide_4_img.png)

::: {.notes}
Let’s now look at the time course of a voxel in the visual coretx. You see that it is noisy and delayed, but it kind of follows the stimulus.
:::

## Resting-state networks

5

Yeo et al., 2011

::: {.notes}

:::

## Other parcellation schemes

6

::: {.notes}

:::

## Typical resting-state fMRI analysis

Preprocessing (like in fMRI)
motion-correction 
distortion correction
Registration to structural space
Mapping to template brain
Extensive denoising (physiological noise removal), typically by yielding residuals of a “noise” GLM containing only noise regressors

Functional “Connectivity” analyses types
Region-to-region correlation
Seed-to-whole brain correlation
Connectivity-derived network-level characteristics

7

::: {.notes}

:::

## Task-based GLM design matrix

time

regressors

::: {.notes}

:::

## Seed-based connectivity

time

regressors

::: {.notes}

:::

## Seed-based connectivity result

10

Multiple comparisons correction over N voxels/surface locations

::: {.notes}

:::

## ROI-to-ROI connectivity

time

regressors

Residuals of the GLM represent unconfounded brain activity

![Slide Image](images/slide_11_img.png)

::: {.notes}

:::

## ROI-to-ROI connectivity

A pairwise correlation of residual time courses

Multiple comparisons correction over N correlations

::: {.notes}

:::

## Group 5

Have

Preprocessed rs-fMRI dataset in volumetric MNI space (also in FreeSurfer surface space if needed)
Nuisance regressors for denoising

To do

Read data in CONN toolbox
Run denoising and first-level analysis
Group analysis depending on research question

13

::: {.notes}

:::

## MVPA

14

::: {.notes}

:::

## Checkerboard experiment

![Slide Image](images/slide_15_img.png)

![Slide Image](images/slide_15_img.png)

::: {.notes}
Let’s now look at the time course of a voxel in the visual coretx. You see that it is noisy and delayed, but it kind of follows the stimulus.
:::

## General Linear Model (GLM)

Important: each voxel is tested for activation independently from all other voxels

![Slide Image](images/slide_16_img.png)

::: {.notes}
However, there is a better way called the General linear model (shortly called glm)
It boils down to making a prediction about the signal time course and comparing this prediction with the measured signal
:::

## Multivariate analysis: Cola vs. Pepsi

Condition A

Condition B

![Slide Image](images/slide_17_img.png)

::: {.notes}

:::

## A widely used method in neuroscience

fMRI
EEG
MEG
Single-cell recordings
Etc., etc.

Analysis of multiple dependent variables (brain signals) simultaneously

::: {.notes}

:::

## First MVPA paper

Haxby et al., Science 2001

Run 1

Run 2

Run 3

Run 4

![Slide Image](images/slide_19_img.png)

![Slide Image](images/slide_19_img.png)

![Slide Image](images/slide_19_img.png)

![Slide Image](images/slide_19_img.png)

![Slide Image](images/slide_19_img.png)

![Slide Image](images/slide_19_img.png)

![Slide Image](images/slide_19_img.png)

![Slide Image](images/slide_19_img.png)

![Slide Image](images/slide_19_img.png)

::: {.notes}

:::

## First MVPA paper

Haxby et al., Science 2001

::: {.notes}

:::

## First MVPA paper

Haxby et al., Science 2001

Representational similarity analysis (RSA)

http://www.pymvpa.org/datadb/haxby2001.html

::: {.notes}

:::

## Main principle: two runs, 3 voxels

Run 2 activity

Run 1 activity

2

faces

houses

1

3

Faces response

Voxel #

1

3

2

::: {.notes}

:::

## Main principle: two runs, 3 voxels

Run 2 activity

Run 1 activity

2

faces

houses

2

1

1

3

3

Faces response

Voxel #

1

3

2

Houses response

1

3

2

Voxel #

![Slide Image](images/slide_23_img.png)

::: {.notes}

:::

## First SVM paper(s): year 2005

Kandel et al., Principles of Neuroscience 2000

Orientation column signal: < 1 mm spatial frequency

::: {.notes}

:::

## First SVM paper(s): year 2005

adapted from Kandel et al., Principles of Neuroscience 2000

Orientation column signal: < 1 mm spatial frequency

![Slide Image](images/slide_25_img.png)

![Slide Image](images/slide_25_img.png)

::: {.notes}

:::

## Main principle: 2D example

https://eight2late.wordpress.com/2017/02/07/a-gentle-introduction-to-support-vector-machines-using-r/

Electrode 2
Voxel 2
Time point 2
Neuron 2

Electrode 1
Voxel 1
Time point 1
Neuron 1

faces

houses

Single trial

Can you tell which trials belong to which condition?

½ of all trials

½ of all trials

![Slide Image](images/slide_26_img.png)

::: {.notes}

:::

## Main principle: 2D example

https://eight2late.wordpress.com/2017/02/07/a-gentle-introduction-to-support-vector-machines-using-r/

Electrode 2
Voxel 2
Time point 2
Neuron 2

Electrode 1
Voxel 1
Time point 1
Neuron 1

faces

houses

Important: you need information from BOTH voxels for correct classification!

![Slide Image](images/slide_27_img.png)

::: {.notes}

:::

## Main principle: 2D example

https://eight2late.wordpress.com/2017/02/07/a-gentle-introduction-to-support-vector-machines-using-r/

Electrode 2
Voxel 2
Time point 2
Neuron 2

Electrode 1
Voxel 1
Time point 1
Neuron 1

faces

houses

Classifier weights of each voxels are useful, but often ignored.

weight

See also: https://en.wikipedia.org/wiki/Support-vector_machine

::: {.notes}

:::

## Training and testing phases

https://eight2late.wordpress.com/2017/02/07/a-gentle-introduction-to-support-vector-machines-using-r/

Electrode 2
Voxel 2
Time point 2
Neuron 2

Electrode 1
Voxel 1
Time point 1
Neuron 1

faces

houses

It is not enough to do the “training”. Testing on a separate set of examples is critical!

See also: https://en.wikipedia.org/wiki/Support-vector_machine

Electrode 1
Voxel 1
Time point 1
Neuron 1

Are these trials really all face trials?

![Slide Image](images/slide_29_img.png)

::: {.notes}

:::

## Classifier performance

Accuracy: % correct
Usually tested statistically against chance level
If significant, voxel response patterns contain information about the stimulus

Signal detection theory measures (see lectures Allgemeine I)

30

::: {.notes}

:::

## Why do classifiers work?

adapted from Kandel et al., Principles of Neuroscience 2000

Orientation column signal: < 1 mm spatial frequency
Voxel size: 2-3 mm3

![Slide Image](images/slide_31_img.png)

::: {.notes}

:::

## In this course: human ocular dominance columns

Kandel et al., 2000

![Slide Image](images/slide_32_img.png)

::: {.notes}
Noch viel wichtiger fuer NeurowissenschaftlerInnen ist es, die Aktivitaet von diesen keinen Strukturen innerhalb der Hirnrinde messen zu koennen. Es gibt einige Beispiele. Ich werde von den Augendominanzsaulen sprechen, mit dennen ich persoenlich zu tun hatte. 
Was sind die Augendominanzsaulien? Das sind Bereiche im primaren visuellen Areal, die die information nur von einem der beiden Augen bekommen. In diesem Beispiel gelb von dem linken Auge, lilla von dem rechten Auge. Diese Information wird spaeter im Gehirn zusammengefueft, um scharferes sehen und vor allem die Tiefenwahrnehmung zu ermoeglichen. Aber before das passiert, bleibt die Information der beiden Augen getrennt.
:::

## Amblyopia

Public domain image

::: {.notes}
Warum sind die Augendominanzsauelen so wichtig? Man glaubt, dass deren Entwicklung und deren Aktivitaet zum Beispiel mit Amblyopie (oder Schwachsichtigkeit) zu tun hat. Sie kennen wahrscheinlich kleine Kinder, die auf einem Auge ein Pflaster haben? Das ist die uebliche Therapie fuer Amblyopie, die versucht, das Auge, das nicht vollstaendig benutzt wird, zum Sehen zu zwingen.
Diese Therapie ist leider nicht ganz effizient,  und viele Leute, die in der Kindheit Schwachsichtigkeit hatten, haben das auch im Erwachsenalter. Sie koennen keine 3D movies schauen und schielen. Wir muessen viel mehr ueber die Informationverarbeitung von beiden Augen, und ueber Augendominanzsauelen verstehen, um das effizienter behandeln zu koennen.
:::

## Adams et al., 2007

![Slide Image](images/slide_34_img.png)

![Slide Image](images/slide_34_img.png)

![Slide Image](images/slide_34_img.png)

::: {.notes}
Bis vor kurzem war die Untersuchung von Augendominanzsaueln bem Mensch nur post morten moeglich. Wie wurde es gemacht? Man hat bei Menschen, die nur ein Auge hatten, nach ihrem Tod  das Gehirn entfernt. Zuerst wurde der Occipitallappen abgeschnitten, wo sich die visuellen Arealen befinden. Dann wurde die graue Substanz – also die Hirnrinde der visuellen Bereiche – abgetrennt und geglaettet, damit man zwischen den Hirnwindugen besser sieht.
Hier ist der Bereich markiert, woe die Augendominanzsauelen auftretten sollen.
:::

## Untitled Slide

![Slide Image](images/slide_35_img.png)

::: {.notes}
Danach wurde die glatte Hirnrinde mit einer speziellen Substanz gefaerbt, die nur die Bereiche faerbt, die wahrend des Lebens aktiv waren – die von dem gesunden Auge. Dadurch konnte man die Augendominanzsaulen auf der Oberflaeche sehen. Von der Oberflaeche gesehen haben sie so ein typeisches Leopartdemuster.
Ziemlich aufwending, nicht wahr?
:::

## fMRT - Experiment

![Slide Image](images/slide_36_img.png)

::: {.notes}
Schoen langsam koennen wir mit modernen Technologien das gleiche beim lebenden Menschen beobachten.
Was wir brauchen ist ein Hochfeldscanner, der uns eine hohe Aufloesung ermoeglicht.
Wir nehmen einen gesunden Probanden und schieben ihn oder sie in den Scnaner hinein. Im Scanner ist ein Bildschirm, auf dem man dynamische Bilder zeigen kann, die die visuellen Areale aktivieren.
:::

## fMRT - Experiment

![Slide Image](images/slide_37_img.png)

::: {.notes}
Wenn man das gleiche Bild zuerst nur durch das linke Auge
:::

## fMRT - Experiment

![Slide Image](images/slide_38_img.png)

::: {.notes}
Und dann nur durch das rechte Auge Zeigt, kann man die ensrpechenden Augendominanzsauelen aktivieren.
:::

## Untitled Slide

![Slide Image](images/slide_39_img.png)

::: {.notes}
Ein kleines Problem gibt es noch. Durch die Hirnwindugen sieht man das typische Augendominanzmuster leider nicht so gut.
:::

## Untitled Slide

![Slide Image](images/slide_40_img.png)

![Slide Image](images/slide_40_img.png)

![Slide Image](images/slide_40_img.png)

::: {.notes}
Darum nehmen wir ein anatomisches Bild, und generieren mittels spezieller Software ein Modell der Hirnoberflaeche. Hier sieht man es in Gelb. Innen ist die Grenze zwischen der grauen und der wissen Substanz, aussen ist die Grenze zwischen der grauen Substanz und der Hirnflussigkeit.
:::

## Untitled Slide

![Slide Image](images/slide_41_img.png)

![Slide Image](images/slide_41_img.png)

::: {.notes}
Wir nehmen dieses 3-Dimentionale Modell, und beginnen, es mittels eines speziellen Komputerprogramms zu glaetten.  Dieses kleine Video zeigt Ihnen den Ablauf.
Als Ergebniss haben wir dann eine flache Gehirnhaelfte ohne Hirnwindungen. In Gelb ist eine Region markiert, wo die Augendominanzsaulen zu sehen sind.
:::

## Ocular dominance columns in vivo

Zaretskaya et al., 2020

![Slide Image](images/slide_42_img.png)

![Slide Image](images/slide_42_img.png)

::: {.notes}
Und hier ist schon mal das ergebniss eines Experiments. 
Zum Vergleich haben wir das Experiment zuerst mit einem typischen 3 Tesla Scanner gemacht, der nur eine sehr maessige Aufloesung ermoeglicht. Sieht man hier im gelben Bereich irgendwas, was wie Augendominanzsauelen ausschaut? Eher nicht oder wenig. Man sieht rote Punkte, die hier das linke Auge räpresentieren und blaue Punkte, die das rechte Auge räpräsentieren, sowohl innerhalb als auch ausserhalb.
:::

## Augendominanzsäulen in vivo

Zaretskaya et al., 2020

![Slide Image](images/slide_43_img.png)

![Slide Image](images/slide_43_img.png)

::: {.notes}
Und hier, zum vergleichen, ist das gleiche Experiment, aber mittels Hochfeldscanner, mit einer viel hoeheren Aufloesung durchgefuehrt. Ich hoffe, sie stimmen mir zu, dass viel mehr gelb und blau im pimaeren visuellen Areal zu finden sind, und dass das Bild unserem Leoparden-Muster ähnlich wird.
:::

## 3x3x3 mm

::: {.notes}
Fuer diejenigen, die nicht ueberzeugt sind, muss ich noch etwas sagen. 
So toll wie post mortem koenenn wir die Sualen noch nicht sehen. Das ist deshalb so, weil die Dicke einer Saule ungefahr 0.8 mm ist, und unsere Aufloesung ist auch 0.8 mm. Deshalb werden wir in den Pixel auf dem Bild, die zur haelfte das linke Auge und zur haelfte das rechte Auge enthalten, nichts finden. Aber die Technologie entwickelt sich rasch, und es wird nicht mehr lange dauren, bist unsere Ergebnisse der Qualitet von post mortem Daten entsprechen.
:::

## Group 6

Have

Preprocessed 9.4 T data from the ODC experiment with 0.8 mm isotropic voxels
1st level GLM fit to quantify functional responses of each voxel to each condition

TODO

Run an RSA or an SVM analysis or both
Possible research questions: compare the two

::: {.notes}

:::

