<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <title>fmri-intro</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-87abec656e2e6915e4522032b718c7a1.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light fullcontent">
  <div class="reveal page-columns page-full">
    <div class="slides page-columns page-full">


<section class="page-columns page-full">
<section id="introduction-to-fmri" class="title-slide slide level1 center page-columns page-full">
<h1>Introduction to fMRI</h1>

<img data-src="images/claus_7TCOR_activity_website.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Visual activity in the human claustrum <span class="citation" data-cites="coates2024">(<a href="#/references" role="doc-biblioref" onclick="">Coates et al. 2024</a>)</span></p>
</footer>
<aside class="notes">
<p>fMRI is a method that allows to non-invasively measure brain activity.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="fmri-in-comparison" class="slide level2 page-columns page-full">
<h2>fMRI in comparison</h2>

<img data-src="images/clipboard-2571024653.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Source: Gazzaniga 5th edition, Figure 3.45</p>
</footer>
<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="mri-scanner-3-tesla" class="slide level2 page-columns page-full">
<h2>MRI scanner: 3 Tesla</h2>

<img data-src="images/B2EFA5A5-4C48-420B-B1D7-6B4D7314DE12.JPG" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p><a href="https://mri-lab.uni-graz.at/" class="uri">https://mri-lab.uni-graz.at/</a></p>
</footer>
<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="mri-scanner-7-tesla" class="slide level2 page-columns page-full">
<h2>MRI scanner: 7 Tesla</h2>

<img data-src="images/clipboard-2316814449.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Image source: Medical University of Vienna</p>
</footer>
<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="mri-scanner-9.4-tesla" class="slide level2 page-columns page-full">
<h2>MRI scanner: 9.4 Tesla</h2>

<img data-src="images/20121211_MRT_MaxPlanck.jpg" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Image source: Max-Planck Institute for Biological Cybernetics, Tübingen</p>
</footer>
<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="types-of-mri-contrasts" class="slide level2">
<h2>Types of MRI contrasts</h2>

<img data-src="images/clipboard-4250173212.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Image source: <a href="https://en.wikipedia.org/wiki/Magnetic_resonance_imaging" class="uri">https://en.wikipedia.org/wiki/Magnetic_resonance_imaging</a></p>
</footer>
</section>
<section id="t1w-in-cognitive-neuroscience" class="slide level2 page-columns page-full">
<h2>T1w in cognitive neuroscience</h2>

<img data-src="images/clipboard-69158076.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Full Segmentation of a T1-weighted scan <span class="citation" data-cites="zaretskaya2018">(<a href="#/references" role="doc-biblioref" onclick="">Zaretskaya et al. 2018</a>)</span></p>
</footer>
<aside class="notes">
<ul>
<li><p>Displaying activity on a high-resolution anatomical scan</p></li>
<li><p>Quantitative morphometry</p>
<ul>
<li><p>Aging</p></li>
<li><p>Neurodegeneration</p></li>
<li><p>Plasticity</p></li>
</ul></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-principle-of-fmri" class="slide level2 page-columns page-full">
<h2>The principle of fMRI</h2>

<img data-src="images/clipboard-1690626376.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Image source: <a href="https://www.nature.com/scitable/blog/brain-metrics/what_does_fmri_measure" class="uri">https://www.nature.com/scitable/blog/brain-metrics/what_does_fmri_measure</a></p>
</footer>
<aside class="notes">
<p>Hemodynamic changes: - increase in blood flow - increase in blood volume - increase in tissue CMRO_2</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="hemodynamic-response" class="slide level2 page-columns page-full">
<h2>Hemodynamic response</h2>

<img data-src="images/ezgif.com-add-text-2.gif" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Source: Visual Neuroscience Lab</p>
</footer>
<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="bold-signal" class="slide level2 page-columns page-full">
<h2>BOLD signal</h2>
<p>blood-oxygen-level-dependent signal</p>

<img data-src="images/clipboard-1557735976.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Hemodynamics leading to the BOLD signal <span class="citation" data-cites="interpre2009">(<a href="#/references" role="doc-biblioref" onclick=""><span>“Interpreting the BOLD Response”</span> 2009</a>)</span></p>
</footer>
<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="t2-weighted-contrast" class="slide level2">
<h2>T2*-weighted contrast</h2>

<img data-src="images/clipboard-1399733517.png" class="r-stretch"></section>
<section id="hemodynamic-response-function" class="slide level2 page-columns page-full">
<h2>Hemodynamic response function</h2>

<img data-src="images/clipboard-1679437843.png" class="r-stretch"><aside class="notes">
<p>This curve describes the measured signal in response to a brief stimulus.</p>
<p>The response is heavily delayed, and has a relatively complex temporal structure, described by the so called hemodynamic response function (HRF).</p>
<p>After just a brief stimulus that lasts less than a second, the response lasts for seconds. It has a delayed rise phase, a peak, and a subsequent undershoot. The fact that the response is so slow is the main constraint of the temporal resolution of fMRI. It constrains the kind of questions you can ask in your experiment and also puts some constraints on your experimental design.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="neural-activity-and-bold" class="slide level2 page-columns page-full">
<h2>Neural activity and BOLD</h2>

<img data-src="images/clipboard-2104563483.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>BOLD signal correlates better with LFP than with MUA <span class="citation" data-cites="logothetis2001a">(<a href="#/references" role="doc-biblioref" onclick="">Logothetis et al. 2001</a>)</span></p>
</footer>
<aside class="notes">
<p>LFP = Local Field Potentials (dendritic currents)</p>
<p>MUA = Multiunit Activity (action potentials)</p>
<p>SDF = Spike-density function (action potentials)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="image-acquisition" class="slide level2 page-columns page-full">
<h2>Image acquisition</h2>

<img data-src="images/clipboard-1936163497.png" class="r-stretch"><aside class="notes">
<p>The functional volume is usually acquired slice-by-slice; this is why when you are acquiring the data you see an image like this on the monitor. A functional sequence is characterized by the in-plane matrix size and resolution, as well as by the slice thickness.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="experimental-design" class="slide level2 page-columns page-full">
<h2>Experimental design</h2>

<img data-src="images/clipboard-3076195966.png" class="r-stretch"><aside class="notes">
<p>In contrast to e.g.&nbsp;fNIRS, the BOLD-fMRI does not measure the deoxyhemoglobin concentration directly. It is a measure that is weighted by the deoxyhemoglobin concentration, but depends on many other factors like scanner, sequence, participant, and brain area.</p>
<p>This is why any measure of fMRI experiment has to contain at least two conditions, a baseline, and condition of interest. The activation is always computed relative to some baseline. For instance a checkerboard vs gray background, finger tapping versus rest; faces versus houses, etc. And a typical analysis will compare the BOLD signal during condition of interest with rest.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="first-fmri-experiment" class="slide level2 page-columns page-full">
<h2>First fMRI experiment</h2>

<img data-src="images/clipboard-2455011416.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Brain images and statistical analysis <span class="citation" data-cites="belliveau1991">(<a href="#/references" role="doc-biblioref" onclick="">Belliveau et al. 1991</a>)</span></p>
</footer>
<aside class="notes">
<p>The first experiment was not a BOLD, but a blood volume signal measurement.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="first-fmri-experiment-1" class="slide level2 page-columns page-full">
<h2>First fMRI experiment</h2>

<img data-src="images/clipboard-460283216.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Cover of the science magazine where the paper was published <span class="citation" data-cites="belliveau1991">(<a href="#/references" role="doc-biblioref" onclick="">Belliveau et al. 1991</a>)</span></p>
</footer>
<aside class="notes">
<p>This rendering was produced specifically for the cover</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-truly-first-fmri-experiment" class="slide level2">
<h2>The truly first fMRI experiment</h2>

<img data-src="images/clipboard-2371383352.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Experimental setup of Angelo Mosso <span class="citation" data-cites="sandrone2013">(<a href="#/references" role="doc-biblioref" onclick="">Sandrone et al. 2013</a>)</span></p>
</footer>
</section>
<section id="a-typical-experiment" class="slide level2 page-columns page-full">
<h2>A typical experiment</h2>

<img data-src="images/clipboard-2847001828.png" class="r-stretch"><aside class="notes">
<p>To help us better understand the analysis steps, let’s use an example. Let’s say we have conducted a classical experiment in the visual system, a flickering checkerboard. In this experiment, we want to find out which brain areas are active when subjects view a flickering checkerboard compared to when they view a gray background. We have shown to every volunteer a checkerboard for e.g.&nbsp;20 second interleaved with a 20 s rest, and we will measure a whole brain volume every 2 seconds, for e.g.&nbsp;to minutes or so.</p>
<p>Matlab code to generate stimulus, BOLD and shifted BOLD X = [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]; bf = spm_get_bf; % indicated a tr of 2.5 Y = conv(X,bf.bf); Ye = Y+randn(size(Y)).*0.2;</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="d-dataset" class="slide level2 page-columns page-full">
<h2>4D dataset</h2>

<img data-src="images/clipboard-531340901.png" class="r-stretch"><aside class="notes">
<p>In a functional experiment we usually measure brain activity across the whole volume over extended periods of time, so it is comfortable to think about each functional dataset that we acquire as a 4D dataset, which consists of 3D brain volumes and time as a 4th dimension. This is how the data is typically stored.</p>
<p>A further important parameter is the repetition time (TR). It is the time passes between the acquisition times of two adjacent volumes.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="preprocessing" class="slide level2 page-columns page-full">
<h2>Preprocessing</h2>

<img data-src="images/clipboard-3600520399.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Summary of preprocessing steps <span class="citation" data-cites="esteban2018">(<a href="#/references" role="doc-biblioref" onclick="">Esteban et al. 2018</a>)</span></p>
</footer>
<aside class="notes">
<p>The data quality of modern scanners is typically good enough to skip this step, if your subject is compliant. But it is nevertheless very much advisable and is ALWAYS performed. We will therefore dedicate a whole session to preprocessing. See <a href="./syllabus.html#tbl-schedule">course schedule</a> for the date.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="analysis" class="slide level2 page-columns page-full">
<h2>Analysis</h2>
<ul>
<li class="fragment"><p>Single-subject - first level - fixed effects analysis (FFX)</p></li>
<li class="fragment"><p>Group - second-level - random effects analysis (RFX)</p></li>
</ul>
<aside class="notes">
<p>This is equivalent to e.g.&nbsp;conducting many trials per subject to measure reaction time, and then compute a subject-specific mean per condition, after which you would perform the actual statistical inference</p>
<p>Multilevel modelling is also possible (for small datasets), but less frequent.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="single-subject-first-level-analysis" class="slide level2 page-columns page-full">
<h2>Single-subject (first-level) analysis</h2>
<p>Univariate/voxel-wise analysis</p>

<img data-src="images/clipboard-3043522045.png" class="r-stretch"><p>Question: Which areas are activated by the flickering checkerboard?</p>
<aside class="notes">
<p>Remember that an image is 4d and consists of little 3D cubes called voxels, with the 4th dimension being time. A classical analysis is done over time for every voxel in the brain independently.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="stimulus-function" class="slide level2 page-columns page-full">
<h2>Stimulus function</h2>

<img data-src="images/clipboard-1888338078.png" class="r-stretch"><aside class="notes">
<p>Let’s recall our checkerboard experiment where participants viewed either a checkerboard or a gray screen. Let’s also create a function, called “stimulus function”, which is one where the checkerboard was on, and zero where the checkerboard was off</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="side-note-on-terminology" class="slide level2">
<h2>Side-note on terminology</h2>
<h3 id="trial">Trial</h3>
<p>Continuous presentation of 1 experimental condition, usually 1-20 seconds</p>
<h3 id="run">Run</h3>
<p>Block of trials separated by interruption of a scanner acquisition, usually 5-10 minutes</p>
<h3 id="session">Session</h3>
<p>Block of runs, separated by subject going out of the scanner and going in again, usually at least one day</p>
</section>
<section id="voxel-time-course" class="slide level2 page-columns page-full">
<h2>Voxel time course</h2>

<img data-src="images/clipboard-1165528043.png" class="r-stretch"><aside class="notes">
<p>Let’s now look at the time course of a voxel in the visual cortex. You see that it is noisy and delayed, but it kind of follows the stimulus.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="simplest-analysis-temporal-alignment" class="slide level2 page-columns page-full">
<h2>Simplest analysis: temporal alignment</h2>

<img data-src="images/clipboard-62469843.png" class="r-stretch"><aside class="notes">
<p>The simplest analysis would be to realign the BOLD time course with the stimulus time course</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="simplest-analysis-statistical-inference" class="slide level2 page-columns page-full">
<h2>Simplest analysis: statistical inference</h2>

<img data-src="images/clipboard-3483010198.png" class="r-stretch"><aside class="notes">
<p>Then labael each value according to when it was acquired, stimulus or baseline Collect two types of data points into two big piles and do a statistical comparison via a t-test</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="simplest-analysis-statistical-map" class="slide level2 page-columns page-full">
<h2>Simplest analysis: statistical map</h2>

<img data-src="images/clipboard-969426715.png" class="r-stretch"><aside class="notes">
<p>If you do it for every voxel, you can get a new volume, which consists of t-statistics</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="general-linear-model-glm" class="slide level2">
<h2>General Linear Model (GLM)</h2>
<p>Multiple regression with ingredients:</p>
<ul>
<li class="fragment"><p>Predictor(s): stimulus function convolved with the HRF (see <a href="#/buidling-regressors">Buidling regressors</a>)</p></li>
<li class="fragment"><p>Nuissance regressors</p></li>
<li class="fragment"><p><img data-src="images/sub-P01_task-localizer_run-1_design.png"></p></li>
</ul>
</section>
<section id="buidling-regressors" class="slide level2">
<h2>Buidling regressors</h2>

<img data-src="images/clipboard-4230244420.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Some convolution examples can be found here <span class="citation" data-cites="lindquist2008">(<a href="#/references" role="doc-biblioref" onclick="">Lindquist 2008</a>)</span></p>
</footer>
</section>
<section id="general-linear-model" class="slide level2">
<h2>General linear model</h2>

<img data-src="images/clipboard-3283349145.png" class="r-stretch"></section>
<section id="statistical-inference-in-whole-brain-analysis" class="slide level2 page-columns page-full">
<h2>Statistical inference in whole-brain analysis</h2>

<img data-src="images/clipboard-3973626449.png" class="r-stretch"><aside class="notes">
<p>How do we get from beta estimates to making statistical inference? As in a typical regression, beta estimate divided by its standard error is a t-statistic with a t-distribution. So to know whether an activation in one voxel is significant is relatively straightforward.</p>
<p>If we had just one voxel, we would have computed the t-statistic, and then depending on the degrees of freedom determined if it exceeds the critical value. However, we are doing the same statistical test for MANY voxels. SO the probability that we find a significant voxel simply by chance increases. This is the multiple comparison problem that is encountered anywhere in statistics. In fMRI it is particularly prominent, because the number if singe tests is enormous. There are several ways and philosophies for dealing with it, I won’t go into details right now. The important thing is that any voxel-wise analysis MUST deal with this problem in some way.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="two-conditions" class="slide level2">
<h2>Two conditions</h2>

<img data-src="images/clipboard-3643081170.png" class="r-stretch"></section>
<section id="general-linear-model-with-two-conditions" class="slide level2">
<h2>General linear model with two conditions</h2>

<img data-src="images/clipboard-632029715.png" class="r-stretch"></section>
<section id="contrast" class="slide level2">
<h2>Contrast</h2>
<p>A linear combination of beta estimates</p>

<img data-src="images/clipboard-3240858118.png" class="r-stretch"></section>
<section id="glm-advantages" class="slide level2">
<h2>GLM advantages</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p><img data-src="images/clipboard-4292960842.png"></p>
</div><div class="column" style="width:40%;">
<ul>
<li class="fragment"><p>Complex experimental designs</p></li>
<li class="fragment"><p>Discounting uninteresting effects/confounds</p></li>
<li class="fragment"><p>HRF shape estimation</p></li>
</ul>
</div></div>
</section>
<section id="group-analysis" class="slide level2">
<h2>Group analysis</h2>

<img data-src="images/clipboard-1995917989.png" class="r-stretch"></section>
<section id="region-of-interest-roi-analysis" class="slide level2 page-columns page-full">
<h2>Region-of-interest (ROI) analysis</h2>

<img data-src="images/clipboard-2858615543.png" class="r-stretch"><p>Question: Does the primary visual cortex respond to flickering checkerboards?</p>
<footer style="font-size: 0.4em; color: gray;">
<p>HCP cortical parcellation (“Glasser atlas”) <span class="citation" data-cites="glasser2016">(<a href="#/references" role="doc-biblioref" onclick="">Glasser et al. 2016</a>)</span></p>
</footer>
<aside class="notes">
<p>ROI analysis is a way to deal with multiple comparison problem. But it requires an a priory and independent definition of an ROI.</p>
<p>There are two ways to define ROIs:</p>
<ul>
<li><p>From an anatomical scan</p></li>
<li><p>From an additional (separate) functional experiment</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="subcortical-rois" class="slide level2 page-columns page-full">
<h2>Subcortical ROIs</h2>

<img data-src="images/next_brain_coronal.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>NextBrain parcellation containing 333 anatomical structures <span class="citation" data-cites="casamitjana2024">(<a href="#/references" role="doc-biblioref" onclick="">Casamitjana et al. 2024</a>)</span></p>
</footer>
<aside class="notes">
<p>This is the state-of-the-art for anatomically-based ROI definition based on deep learning</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="multivariate-pattern-analysis" class="slide level2 page-columns page-full">
<h2>Multivariate pattern analysis</h2>

<img data-src="images/clipboard-3955080845.png" class="r-stretch"><p>Question: Is the voxel response <em>pattern</em> different in condition A and B?</p>
<aside class="notes">
<p>Remember that an image is 4d and consists of little 3d cubes called voxels, with the 4th dimension being time. A classical analysis is done over time for every voxel in the brain independently. In a multivariate analysis we first perform a univariate analysis and then look at response patterns of multiple voxels at a time.</p>
<p>In this example, both coca cola and pepsi activate the same 6 voxels in the visual cortex. But the red ones are activated more by cola then by pepsi, and the blue ones the other way around. If you just look at the average response over 6 voxels, you will not see a difference.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="searchlight-analysis" class="slide level2 page-columns page-full">
<h2>Searchlight analysis</h2>

<img data-src="images/clipboard-137996085.png" class="r-stretch"><aside class="notes">
<p>MVPA can be done for a region of interest, or for the entire brain. In the latter case, the brain is subdivided into multiple ROIs, and the relevant analysis is performed for each of them. This procedure is called “searchlight”. In this case, MCC is as relevant as it is in a univariate analysis.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="first-mvpa-paper" class="slide level2">
<h2>First MVPA paper</h2>

<img data-src="images/clipboard-1666315153.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Representation similarity analysis <span class="citation" data-cites="haxby2001">(<a href="#/references" role="doc-biblioref" onclick="">Haxby et al. 2001</a>)</span></p>
</footer>
</section>
<section id="machine-learning" class="slide level2">
<h2>Machine learning</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="images/clipboard-3573273781.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="images/clipboard-2352405043.png"></p>
</div></div>
<footer style="font-size: 0.4em; color: gray;">
<p>First MVPA papers, both appeared in 2005 <span class="citation" data-cites="haynes2005 kamitani2005">(<a href="#/references" role="doc-biblioref" onclick="">Haynes and Rees 2005</a>; <a href="#/references" role="doc-biblioref" onclick="">Kamitani and Tong 2005</a>)</span></p>
</footer>
</section>
<section id="svm-classifier" class="slide level2">
<h2>SVM classifier</h2>

<img data-src="images/clipboard-845253526.png" class="r-stretch"><footer style="font-size: 0.4em; color: gray;">
<p>Toy example for 2D feature space. Further reading in e.g.&nbsp;Cohen et al. <span class="citation" data-cites="cohen2017">(<a href="#/references" role="doc-biblioref" onclick="">2017</a>)</span></p>
</footer>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-belliveau1991" class="csl-entry" role="listitem">
Belliveau, J. W., D. N. Kennedy, R. C. McKinstry, B. R. Buchbinder, R. M. Weisskoff, M. S. Cohen, J. M. Vevea, T. J. Brady, and B. R. Rosen. 1991. <span>“Functional Mapping of the Human Visual Cortex by Magnetic Resonance Imaging.”</span> <em>Science</em> 254 (5032): 716–19. <a href="https://doi.org/10.1126/science.1948051">https://doi.org/10.1126/science.1948051</a>.
</div>
<div id="ref-casamitjana2024" class="csl-entry" role="listitem">
Casamitjana, Adrià, Matteo Mancini, Eleanor Robinson, Loïc Peter, Roberto Annunziata, Juri Althonayan, Shauna Crampsie, et al. 2024. <span>“A Next-Generation, Histological Atlas of the Human Brain and Its Application to Automated Brain MRI Segmentation.”</span> <a href="http://dx.doi.org/10.1101/2024.02.05.579016">http://dx.doi.org/10.1101/2024.02.05.579016</a>.
</div>
<div id="ref-coates2024" class="csl-entry" role="listitem">
Coates, Adam, David Linhardt, Christian Windischberger, Anja Ischebeck, and Natalia Zaretskaya. 2024. <span>“High-Resolution 7T fMRI Reveals the Visual Zone of the Human Claustrum.”</span> <em>Imaging Neuroscience</em> 2: 1–15. <a href="https://doi.org/10.1162/imag_a_00327">https://doi.org/10.1162/imag_a_00327</a>.
</div>
<div id="ref-cohen2017" class="csl-entry" role="listitem">
Cohen, Jonathan D, Nathaniel Daw, Barbara Engelhardt, Uri Hasson, Kai Li, Yael Niv, Kenneth A Norman, et al. 2017. <span>“Computational Approaches to fMRI Analysis.”</span> <em>Nature Neuroscience</em> 20 (3): 304–13. <a href="https://doi.org/10.1038/nn.4499">https://doi.org/10.1038/nn.4499</a>.
</div>
<div id="ref-esteban2018" class="csl-entry" role="listitem">
Esteban, Oscar, Christopher J. Markiewicz, Ross W. Blair, Craig A. Moodie, A. Ilkay Isik, Asier Erramuzpe, James D. Kent, et al. 2018. <span>“fMRIPrep: A Robust Preprocessing Pipeline for Functional MRI.”</span> <em>Nature Methods</em> 16 (1): 111–16. <a href="https://doi.org/10.1038/s41592-018-0235-4">https://doi.org/10.1038/s41592-018-0235-4</a>.
</div>
<div id="ref-glasser2016" class="csl-entry" role="listitem">
Glasser, Matthew F., Timothy S. Coalson, Emma C. Robinson, Carl D. Hacker, John Harwell, Essa Yacoub, Kamil Ugurbil, et al. 2016. <span>“A Multi-Modal Parcellation of Human Cerebral Cortex.”</span> <em>Nature</em> 536 (7615): 171–78. <a href="https://doi.org/10.1038/nature18933">https://doi.org/10.1038/nature18933</a>.
</div>
<div id="ref-haxby2001" class="csl-entry" role="listitem">
Haxby, J V, M I Gobbini, M L Furey, A Ishai, J L Schouten, and P Pietrini. 2001. <span>“Distributed and Overlapping Representations of Faces and Objects in Ventral Temporal Cortex.”</span> <em>Science (New York, N.Y.)</em> 293 (5539): 2425–30. <a href="https://doi.org/10.1126/science.1063736">https://doi.org/10.1126/science.1063736</a>.
</div>
<div id="ref-haynes2005" class="csl-entry" role="listitem">
Haynes, John-Dylan, and Geraint Rees. 2005. <span>“Predicting the Orientation of Invisible Stimuli from Activity in Human Primary Visual Cortex.”</span> <em>Nature Neuroscience</em> 8 (5): 686–91. <a href="https://doi.org/10.1038/nn1445">https://doi.org/10.1038/nn1445</a>.
</div>
<div id="ref-interpre2009" class="csl-entry" role="listitem">
<span>“Interpreting the BOLD Response.”</span> 2009. In, 400–424. Cambridge University Press. <a href="https://doi.org/10.1017/cbo9780511605505.020">https://doi.org/10.1017/cbo9780511605505.020</a>.
</div>
<div id="ref-kamitani2005" class="csl-entry" role="listitem">
Kamitani, Yukiyasu, and Frank Tong. 2005. <span>“Decoding the Visual and Subjective Contents of the Human Brain.”</span> <em>Nature Neuroscience</em> 8 (5): 679–85. <a href="https://doi.org/10.1038/nn1444">https://doi.org/10.1038/nn1444</a>.
</div>
<div id="ref-lindquist2008" class="csl-entry" role="listitem">
Lindquist, Martin A. 2008. <span>“The Statistical Analysis of fMRI Data.”</span> <em>Statistical Science</em> 23 (4). <a href="https://doi.org/10.1214/09-sts282">https://doi.org/10.1214/09-sts282</a>.
</div>
<div id="ref-logothetis2001a" class="csl-entry" role="listitem">
Logothetis, Nikos K., Jon Pauls, Mark Augath, Torsten Trinath, and Axel Oeltermann. 2001. <span>“Neurophysiological Investigation of the Basis of the fMRI Signal.”</span> <em>Nature</em> 412 (6843): 150–57. <a href="https://doi.org/10.1038/35084005">https://doi.org/10.1038/35084005</a>.
</div>
<div id="ref-sandrone2013" class="csl-entry" role="listitem">
Sandrone, Stefano, Marco Bacigaluppi, Marco R. Galloni, Stefano F. Cappa, Andrea Moro, Marco Catani, Massimo Filippi, Martin M. Monti, Daniela Perani, and Gianvito Martino. 2013. <span>“Weighing Brain Activity with the Balance: Angelo Mosso<span>’</span>s Original Manuscripts Come to Light.”</span> <em>Brain</em> 137 (2): 621–33. <a href="https://doi.org/10.1093/brain/awt091">https://doi.org/10.1093/brain/awt091</a>.
</div>
<div id="ref-zaretskaya2018" class="csl-entry" role="listitem">
Zaretskaya, Natalia, Bruce Fischl, Martin Reuter, Ville Renvall, and Jonathan R Polimeni. 2018. <span>“Advantages of Cortical Surface Reconstruction Using Submillimeter 7 t MEMPRAGE.”</span> <em>NeuroImage</em> 165 (January): 11–26. <a href="https://doi.org/10.1016/j.neuroimage.2017.09.060">https://doi.org/10.1016/j.neuroimage.2017.09.060</a>.
</div>
</div>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="logo/logo.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>